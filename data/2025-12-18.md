<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.LG](#cs.LG) [Total: 58]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 本文挑战了OpenAI关于大语言模型幻觉源于评估激励不当的观点，提出幻觉是Transformer架构的结构性必然，而非可通过优化激励解决的偶然行为问题。


<details>
  <summary>Details</summary>
Motivation: OpenAI认为大语言模型的幻觉主要源于评估激励不当，奖励自信猜测而非认知谦逊，因此幻觉是可通过改进基准和奖励结构修复的偶然行为。本文旨在挑战这一解释，论证幻觉是Transformer模型的结构性必然。

Method: 结合先前关于结构性幻觉的研究，使用许可预言机（Licensing Oracle）进行实证实验，分析Transformer的嵌入空间形成基于语言共现而非世界指称结构的伪本体论，在训练数据稀疏或不连贯的本体边界条件下，模型必然通过虚构延续来保持连贯性。

Result: 实证结果表明，幻觉只能通过外部真实验证和弃权模块消除，而不能通过改变激励、提示或微调来解决。许可预言机之所以能在各领域实现完美的弃权精度，正是因为它提供了Transformer所缺乏的基础。

Conclusion: 幻觉是生成架构的结构性属性，可靠的AI需要混合系统来区分语言流畅性和认知责任。Transformer不表示世界，而是建模标记间的统计关联，其模式完成的结构性依赖无法通过激励机制改变。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [2] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2是基于Gemma 3模型构建的轻量级多模态编码器-解码器模型，通过改进的UL2适应策略将纯解码器模型转换为编码器-解码器架构，并引入了共享嵌入和合并注意力等效率优化技术。


<details>
  <summary>Details</summary>
Motivation: 开发新一代轻量级开放编码器-解码器模型，增强多语言、多模态和长上下文处理能力，同时保持或超越原始Gemma 3模型的性能。

Method: 采用T5Gemma的UL2适应策略，将预训练的解码器模型转换为编码器-解码器架构，并扩展到多模态领域。提出两种效率改进方法：1）共享编码器和解码器的词嵌入；2）将解码器的自注意力和交叉注意力合并为单一联合模块。

Result: 实验证明适应策略在不同架构和模态上具有通用性，编码器-解码器架构在长上下文建模方面具有独特优势。T5Gemma 2在预训练性能上与Gemma 3相当或更好，在后训练性能上显著提升。

Conclusion: T5Gemma 2成功扩展了编码器-解码器适应策略到多模态领域，通过效率优化技术实现了性能提升，发布了270M-270M、1B-1B和4B-4B三个规模的预训练模型供社区使用。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [3] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 本文改进了新闻观点分类流程，通过微调大语言模型和用Wikidata丰富实体表示来提升分类性能，在英国移民辩论数据集上验证了最佳效果。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体在民主社会中通过特定话题、观点和声音塑造政治社会话语，理解这些动态对于评估媒体是否提供平衡公正的公共辩论至关重要。之前的研究虽然建立了观点识别和分类流程，但仍有改进空间。

Method: 1) 微调大语言模型用于观点分类；2) 利用Wikidata提取相关参与者的语义描述来丰富声明表示。这两种机制可以独立使用，也可以集成应用。

Result: 在英国移民辩论基准测试中，两种机制都能独立提升分类性能，但集成使用时效果最佳，特别是使用能够处理长输入的大语言模型时。

Conclusion: 通过结合微调大语言模型和语义丰富的实体表示，可以显著提升新闻观点分类的准确性和效果，这对于分析媒体话语平衡性具有重要意义。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [4] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在药学执照考试式问答任务上的表现，并开发了DrugRAG外部知识整合方法来提升模型准确性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在药学专业任务上的表现，并开发一种无需修改模型架构的外部知识整合方法，以提高模型在药学问答任务中的准确性。

Method: 使用包含141个问题的药学数据集对11个不同参数规模（80亿到700+亿）的LLM进行基准测试，测量各模型的基线准确率。开发了名为DrugRAG的三步检索增强生成管道，从已验证来源检索结构化药物知识，并将基于证据的上下文信息添加到模型提示中，该方法在模型外部运行，无需修改模型架构或参数。

Result: 基线准确率范围为46%到92%，GPT-5（92%）和o3（89%）得分最高。参数少于80亿的模型得分低于50%。DrugRAG显著提高了所有测试模型的准确率，提升幅度为7到21个百分点（例如：Gemma 3 27B从61%提升到71%，Llama 3.1 8B从46%提升到67%）。

Conclusion: 通过DrugRAG整合外部结构化药物知识，无需修改底层模型即可显著提高LLM在药学任务上的准确性。该方法为增强药学领域AI应用提供了实用的基于证据的信息整合管道。

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [5] [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)
*Caner Erden*

Main category: cs.CL

TL;DR: MAHA提出了一种多尺度聚合层次注意力机制，通过层次分解和数学严谨的聚合策略，在保持全局依赖关系的同时显著降低计算复杂度，为长上下文LLM提供可扩展解决方案。


<details>
  <summary>Details</summary>
Motivation: 多头自注意力的二次计算复杂度限制了大型语言模型在长上下文任务中的扩展。现有的稀疏和线性化注意力机制要么损害全局依赖表示，要么无法有效捕捉多尺度语义粒度。

Method: MAHA通过可学习的下采样算子将输入序列动态划分为层次尺度，核心创新在于将尺度特定注意力矩阵的融合建模为资源分配问题，采用凸优化框架或基于纳什均衡的博弈论方法求解，确保局部细节与全局上下文保真度的理论最优平衡。该方法在混合扩张卷积transformer骨干中实现，使用可微分优化层支持端到端训练。

Result: 实验评估显示MAHA具有优越的可扩展性；在序列长度为4096时，经验FLOPs分析确认计算成本比标准注意力降低81%。

Conclusion: MAHA弥合了优化理论与序列建模之间的差距，为下一代LLM提供了可扩展的解决方案，在保持全局依赖表示的同时显著降低计算复杂度。

Abstract: The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global dependencies or fail to capture multiscale semantic granularity effectively. In this paper, we propose Multiscale Aggregated Hierarchical Attention (MAHA), a novel architectural framework that reformulates the attention mechanism through hierarchical decomposition and mathematically rigorous aggregation. Unlike conventional approaches that treat token interactions at a single resolution, MAHA dynamically partitions the input sequence into hierarchical scales via learnable downsampling operators. The core innovation lies in its aggregation strategy: we model the fusion of scalespecific attention matrices as a resource allocation problem, solved via a convex optimization framework or a Nash equilibriumbased gametheoretic approach. This ensures a theoretically optimal balance between local nuance and global context fidelity. Implemented within a hybrid dilatedconvolutional transformer backbone, MAHA utilizes differentiable optimization layers to enable endtoend training. Experimental evaluations demonstrate that MAHA achieves superior scalability; empirical FLOPs analysis confirms an 81% reduction in computational cost at a sequence length of 4096 compared to standard attention. This work bridges the gap between optimization theory and sequence modeling, offering a scalable solution for nextgeneration LLMs.

</details>


### [6] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 将Flickr30k数据集翻译为罗马尼亚语并扩展为视觉问答数据集，用于提升罗马尼亚语多模态AI能力


<details>
  <summary>Details</summary>
Motivation: 关注低资源语言是民主化生成式AI的重要步骤，需要减少罗马尼亚语在多模态NLP领域的资源差距

Method: 1) 将Flickr30k数据集翻译为罗马尼亚语；2) 利用开源LLM扩展为视觉问答数据集；3) 在LLaMA 3.2、LLaVA 1.6和Qwen2模型家族上使用LoRA方法进行微调

Result: 微调后的模型在罗马尼亚语视觉问答能力上显著提升，Qwen2-VL-RoVQA在BERTScore F1上分别提升6.05%和2.61%，语法错误大幅减少，在未训练的图像描述生成任务上也表现出色

Conclusion: 通过创建罗马尼亚语多模态数据集和微调开源VLM，成功提升了罗马尼亚语的多模态AI能力，为低资源语言AI民主化提供了可行方案

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [7] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 该研究系统评估了40个多模态大语言模型在化学奥林匹克竞赛题目上的表现，发现当前模型在跨模态融合方面存在显著缺陷，移除图像有时反而提高准确率，而思维链提示能有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态科学推理，特别是在化学领域，对大型语言模型仍是一个重大挑战。化学问题解决依赖于符号图表、分子结构和结构化视觉数据，需要跨模态的整合推理能力。当前模型在这方面的表现需要系统评估。

Method: 研究系统评估了40个专有和开源的多模态大语言模型（包括GPT-5、o3、Gemini-2.5-Pro、Qwen2.5-VL等），使用基于20多年美国国家化学奥林匹克竞赛试题构建的基准测试。这些题目需要跨多种模态的视觉和文本整合推理。研究采用思维链提示、消融研究和基于遮挡的可解释性分析等方法。

Result: 研究发现许多模型在模态融合方面表现不佳，在某些情况下移除图像反而提高了准确率，表明视觉-语言整合存在错位。思维链提示能持续提升准确率和视觉基础性。研究揭示了当前多模态大语言模型在科学推理能力上的关键局限性。

Conclusion: 该工作为衡量领域特定多模态AI进展提供了及时的基准测试，强调了在人工智能与科学推理交叉领域需要进一步发展的必要性。研究结果为开发更鲁棒和可解释的化学多模态系统提供了可操作的策略。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [8] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: 提出DASH-DTS框架，基于LLM进行对话主题分割，针对海事VHF对话等非正式语音场景，通过对话握手识别、相似性引导示例选择和选择性样本生成提升分割性能，并发布首个真实海事VHF数据集VHF-Dial。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理任务导向的公共频道通信（如海事VHF对话）时存在局限，这些对话具有非正式语音和隐式主题转换的特点，需要更有效的主题分割方法。

Method: 提出DASH-DTS框架：1) 通过对话握手识别检测主题转换；2) 使用相似性引导的示例选择进行上下文增强；3) 生成选择性正负样本以提高模型判别力和鲁棒性。框架还提供可解释的推理和置信度评分。

Result: 在VHF-Dial数据集和标准基准测试上取得了最先进的分割可信准确率，为操作对话的稳定监控和决策支持奠定了坚实基础。

Conclusion: DASH-DTS框架有效解决了非正式语音对话中的主题分割问题，通过创新的LLM应用方法提升了分割性能，同时发布的VHF-Dial数据集将推动该领域研究发展。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [9] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: SGM是一种白盒神经元级多模态干预方法，通过选择性重新校准有毒专家神经元来减轻多模态大语言模型的毒性，无需参数更新，在标准对抗条件下都能有效降低有害率。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型从弱监督的预训练语料中继承了有毒、偏见和NSFW信号，存在安全风险，特别是在对抗性触发条件下，现有的后期、不透明的免训练去毒方法难以处理。

Method: 提出SGM方法，这是一种白盒神经元级多模态干预技术，类似于为有毒神经元戴上"安全眼镜"。它通过专业知识加权的软抑制选择性重新校准一小部分有毒专家神经元，中和有害的跨模态激活，无需任何参数更新。

Result: 建立了MM-TOXIC-QA多模态毒性评估框架，实验表明SGM在开源MLLMs上能有效减轻标准条件和对抗条件下的毒性，将有害率从48.2%降至2.5%，同时保持流畅性和多模态推理能力。

Conclusion: SGM是可扩展的，其组合防御SGM*能与现有去毒方法集成以提供更强的安全性能，为毒性控制的多模态生成提供了一个可解释、低成本的解决方案。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [10] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 本文提出了元提示协议，一个将大语言模型编排为可编程自优化系统的理论框架，通过对抗三元组架构解决LLM在关键任务应用中缺乏确定性保证的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型从随机聊天接口向可靠软件组件转型需要重新设计交互范式。当前基于启发式的"提示工程"方法无法为关键任务应用提供确定性保证。

Method: 引入元提示协议，采用对抗三元组拓扑结构：生成器(P)、审计器(A)和优化器(O)。将自然语言指令视为语义计算图中的可微分变量，利用文本批评作为梯度，通过声明式编程范式(DSPy)和自动文本微分(TextGrad)实现。

Result: 该架构理论上能够缓解幻觉问题并防止模型崩溃，为概率计算时代的"可观测软件工程"奠定基础。

Conclusion: 元提示协议为将大语言模型转变为可靠软件组件提供了理论框架，通过对抗三元组架构和文本梯度优化，实现了LLM编排的可编程性和自优化能力。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [11] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: SCOPE框架通过集成模型置信度和动态子群划分，改进了测试时强化学习中基于多数投票的伪标签估计方法，解决了确认偏差和稀疏奖励问题，在多个基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 测试时强化学习使用多数投票结果作为伪标签来减少对标注数据的依赖，但这种方法容易产生确认偏差且面临稀疏奖励问题，限制了大型语言模型推理能力的提升。

Method: 提出SCOPE框架：1）将逐步置信度集成到伪标签推导中，优先考虑高质量推理路径而非简单频率计数；2）通过平衡推理质量和探索多样性，动态将候选输出池划分为独立子群；3）通过每个子群的重复采样获得局部共识，提供多样化监督目标以鼓励更广泛的探索。

Result: 在多种模型和基准测试上的实验表明，SCOPE始终优于现有基线方法。在具有挑战性的AIME 2025上相对提升13.1%，在AMC上相对提升8.1%。

Conclusion: SCOPE通过集成模型置信度和动态子群划分，有效解决了测试时强化学习中的确认偏差和稀疏奖励问题，显著提升了大型语言模型的推理能力，为强化学习与可验证奖励的互补方向提供了有效解决方案。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [12] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 本文介绍了乐天旅行评论的大规模语料库，包含2009-2024年共730万条客户评论，提供丰富的元数据和统计信息，并分析2019-2024年间的数据漂移因素。


<details>
  <summary>Details</summary>
Motivation: 构建一个大规模、时间跨度长的旅行评论数据集，为研究数据漂移、用户行为分析、推荐系统等提供基础资源。

Method: 收集乐天旅行平台2009-2024年间的730万条客户评论，包含文本、回复、元数据和多维度评分，使用统计方法分析数据特征和漂移因素。

Result: 创建了包含730万条评论、16年时间跨度的完整数据集，提供了详细的统计信息，并识别出2019-2024年间数据漂移的关键驱动因素。

Conclusion: 该语料库为旅行领域研究提供了宝贵资源，特别是对数据漂移分析具有重要意义，有助于理解用户行为随时间的变化。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [13] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 论文探讨了自然语言生成评估与芬兰大学学生评分之间的认识论平行性，指出两者都存在"大错位问题"，并提出基于过程的P-MFA评估模型


<details>
  <summary>Details</summary>
Motivation: 随着学生越来越多地使用ChatGPT等工具生成复杂输出，传统的基于最终产品的评估方法已失去有效性，需要新的评估框架来应对这一挑战

Method: 引入教学多因素评估（P-MFA）模型，这是一个基于过程的多证据框架，灵感来源于多因素认证的逻辑

Result: 论文提出了一个理论框架，旨在解决评估中的"大错位问题"，但具体实证结果在摘要中未提及

Conclusion: 需要从基于产品的评估转向基于过程的评估，P-MFA模型为解决AI时代的教育评估挑战提供了新的理论框架

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [14] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: RFKG-CoT提出了一种改进的知识图谱增强推理方法，通过关系驱动的自适应跳数选择器和少样本上下文学习路径指导机制，显著提升LLM在知识密集型QA中的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如KG-CoT在集成知识图谱路径时存在两个主要问题：1）僵化的跳数选择（仅基于问题驱动），2）对推理路径的利用不足（缺乏指导）。这导致LLM在知识密集型QA中仍会产生幻觉。

Method: 1）关系驱动的自适应跳数选择器：根据激活的知识图谱关系动态调整推理步数（如直接"兄弟"关系用1跳，间接"父子"链用2跳），通过关系掩码形式化实现。2）少样本上下文学习路径指导机制：以"问题-路径-答案"格式构建示例，结合思维链（CoT）增强LLM对推理路径的理解能力。

Result: 在四个KGQA基准测试中，RFKG-CoT相比KG-CoT在Llama2-7B模型上最高提升14.7个百分点（WebQSP数据集）。消融实验证实跳数选择器和路径提示是互补的，共同将KG证据转化为更可靠的答案。

Conclusion: RFKG-CoT通过自适应跳数选择和路径指导机制，有效解决了现有知识图谱增强方法的局限性，显著提升了LLM在知识密集型QA任务中的可靠性和准确性。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [15] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: Yes-MT团队在WMT 2024低资源印度语言翻译任务中，针对英语与阿萨姆语、米佐语、卡西语、曼尼普尔语之间的翻译，探索了多种方法，包括微调预训练模型、LoRA微调、零/少样本提示LLM、从头训练Transformer等，评估了不同方法在低资源翻译任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决低资源印度语言（阿萨姆语、米佐语、卡西语、曼尼普尔语）与英语之间的机器翻译问题，探索在数据稀缺情况下各种先进方法的有效性，特别是大型语言模型在低资源翻译任务中的潜力。

Method: 1. 微调预训练模型：包括mT5和IndicBart的多语言和单语言设置；2. LoRA微调IndicTrans2；3. 使用Llama 3和Mixtral 8x7b等大型语言模型进行零样本和少样本提示；4. Llama 3的LoRA监督微调；5. 从头训练Transformer模型。

Result: 使用WMT23低资源印度语言翻译共享任务的测试数据，通过SacreBLEU和CHRF指标进行评估，结果显示低资源翻译面临挑战，但大型语言模型特别是经过微调后在这些任务中展现出潜力。

Conclusion: 低资源语言翻译仍然具有挑战性，但大型语言模型通过适当的微调方法（如LoRA）在这些任务中显示出显著潜力，为低资源机器翻译提供了有前景的研究方向。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [16] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: FAME是一个用于评估大语言模型机器遗忘能力的多语言合成基准，包含1000个虚构演员传记和20000个问答对，支持实体级和实例级遗忘评估，覆盖英语、法语、德语、意大利语和西班牙语五种语言。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型机器遗忘评估基准存在两个主要限制：仅关注英语，且仅支持实体级遗忘（即完全删除某个人的所有信息）。这限制了机器遗忘技术在多语言环境下的系统评估和比较。

Method: 研究者创建了FAME基准，包含1000个虚构演员的合成传记，每个传记包含20个主题信息，组织成结构化类别（传记、职业、成就、个人信息）。生成20000个问答对，提供两个数据集分割以支持实体级和实例级遗忘场景。使用虚构数据确保模型在预训练期间从未接触过这些信息。

Result: FAME基准提供了系统评估机器遗忘技术的能力，支持跨五种语言的比较，能够区分实体级遗忘（完全删除身份）和实例级遗忘（删除特定事实同时保留其他信息）。

Conclusion: FAME基准解决了现有机器遗忘评估的局限性，为多语言环境下的机器遗忘技术提供了受控、系统的评估框架，支持更全面的遗忘能力测试和跨语言比较。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [17] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500是一个包含500份澳大利亚全科医疗记录的合成数据集，通过临床医生策划，整合了课程要求、流行病学数据和多样化咨询情境，旨在支持澳大利亚全科医疗临床NLP方法的开发与评估。


<details>
  <summary>Details</summary>
Motivation: 解决澳大利亚全科医疗领域缺乏高质量、隐私安全的临床文本数据集的空白，同时克服自然发生病例分布的限制，提供更全面的训练数据以支持更通用的模型训练。

Method: 采用临床医生策划的方法，整合RACGP 2022课程要求、BEACH研究的流行病学数据，设计包含常见和罕见病例的多样化咨询情境，并故意加入真实医疗记录中的复杂性元素（如简写、拼写错误、患者不依从等）。

Result: 通过多维度验证显示数据集质量：与真实澳大利亚GP咨询模式的流行病学对齐、语言变异度高、语义覆盖广泛，在自监督医疗概念提取任务中展示了F1分数的提升。

Conclusion: SynGP500填补了澳大利亚全科医疗领域的关键数据空白，为研究人员和教育工作者提供了开发评估临床NLP方法的资源，同时天然保护患者隐私，支持更通用化的模型训练。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [18] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: 本文提出了一种名为渐进前缀标记策略优化（PPPO）的新RLVR方法，专注于优化LLM生成输出的前缀部分，通过渐进前缀保留和延续累积奖励两种策略，显著提升了推理性能，仅用26.17%的训练标记就实现了18.02%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法对所有生成标记进行统一训练，忽视了哪些标记（如前缀标记）真正对推理有贡献。这种均匀训练策略在优化低回报标记上花费了大量精力，阻碍了高回报标记的潜在改进，降低了整体训练效率。

Method: 提出了渐进前缀标记策略优化（PPPO）方法，基于路径依赖理论和开始锁定效应（BLE）的发现，专注于优化LLM的前缀推理过程。引入了两种训练策略：1）渐进前缀保留：通过增加训练中保留前缀标记的比例来塑造渐进学习过程；2）延续累积奖励：通过为一个前缀标记序列采样多个延续并累积其分数作为奖励信号来减轻奖励偏差。

Result: 在各种推理任务上的广泛实验结果表明，PPPO优于代表性的RLVR方法，仅使用26.17%的训练标记就实现了18.02%的准确率提升。

Conclusion: PPPO通过专注于优化LLM的前缀推理过程，有效提升了训练效率和推理性能，证明了在RLVR中识别和优化关键标记（特别是前缀标记）的重要性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [19] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 该研究评估了不同提示策略在LLMs提取沸石合成实验信息中的效果，发现LLMs在事件分类上表现良好（80-90% F1），但在细粒度参数提取任务上表现一般（50-65% F1），高级提示策略相比零样本方法改进有限。


<details>
  <summary>Details</summary>
Motivation: 现有方法尚未系统评估LLMs在沸石合成实验信息提取这一领域特定任务中的效果，需要研究不同提示策略在科学信息提取中的有效性。

Method: 研究评估了四种提示策略（零样本、少样本、事件特定、反思式）在六个先进LLMs上的表现，使用ZSEE数据集的1,530个标注句子，关注四个关键子任务：事件类型分类、触发文本识别、论元角色提取和论元文本提取。

Result: LLMs在事件类型分类上表现强劲（80-90% F1），但在细粒度提取任务上表现一般，特别是论元角色和论元文本提取（50-65% F1）。GPT-5-mini表现出极端的提示敏感性（11-79% F1变化）。高级提示策略相比零样本方法改进有限，揭示了架构局限性。

Conclusion: 虽然LLMs实现了高层次理解，但精确提取实验参数需要领域适应模型。研究为科学信息提取提供了定量基准，并识别了系统幻觉、过度泛化和无法捕捉合成特定细微差别等局限性。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [20] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 应用Brookes分类离散度指标(Δ)分析当代阿拉伯应用语言学研究的主题结构，基于2019-2025年1564篇文献，发现Δ=0.194的极低离散度值，表明该领域存在极端主题分散而非集中。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在分析当代阿拉伯应用语言学研究的主题结构特征，通过应用Brookes分类离散度指标来量化该领域的主题分布模式，为理解该学科的发展现状提供实证依据。

Method: 使用Brookes分类离散度指标(Δ)，基于2019-2025年期间1564篇阿拉伯应用语言学出版物构成的真实数据集，将文献分类到八个核心子学科中，计算主题离散度指数。

Result: 计算得到Δ=0.194的极低离散度值，表明阿拉伯应用语言学领域存在极端主题分散；识别出计算语言学作为主导但非霸权力量，与社会语言学、语言教学等其他子领域共存；验证了Brookes公式的正确应用。

Conclusion: 阿拉伯应用语言学领域呈现显著异质性而非集中性；研究展示了Brookes指标在领域特征描述中的实用性，并提供了可复制的文献计量学方法来评估跨领域的学科结构。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [21] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 研究发现将提示改写为诗歌形式是一种有效的对抗性攻击机制，能够显著提高大型语言模型的安全失败率，揭示了当前对齐机制对表面模式的过度依赖。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索诗歌形式的提示如何成为对抗对齐LLM的有效机制，以及当前对齐机制在面对语义形式变化时的脆弱性。特别关注葡萄牙语这种具有高度形态句法复杂性和丰富韵律传统的语言在评估中的缺失。

Method: 研究采用诗歌形式的对抗性提示作为单轮越狱机制，通过手动编写和自动生成的诗歌测试不同对齐方法（RLHF、宪法AI、混合流程）的模型。使用MLCommons AILuminate基准进行安全失败率评估。

Result: 诗歌形式的提示能显著提高安全失败率：手动诗歌达到约62%的攻击成功率，自动版本达43%，某些模型在单轮交互中超过90%成功率。这种效果是结构性的，所有训练方法都表现出一致的性能下降。

Conclusion: 诗歌形式的对抗性提示揭示了当前对齐机制的根本局限性，即过度依赖表面模式而缺乏深层语义理解。研究特别指出葡萄牙语评估的缺失是一个关键空白，需要参数化韵律、格律和韵律变化来测试特定于葡语模式的漏洞。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [22] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: Denser框架通过区分推理和回答阶段的信息密度，使用压缩符号化语言进行中间推理，同时保持人类可读的最终答案，将token消耗减少高达62%


<details>
  <summary>Details</summary>
Motivation: 当前LLM在复杂推理任务中，对中间推理过程和最终答案使用统一的语言密度，导致计算效率低下。研究发现推理过程服务于模型自身的计算功能，而回答服务于人类理解，这种区别使得可以使用压缩符号化语言进行中间计算

Method: 提出Denser框架，包含三个组件：1) 查询处理模块分析输入问题；2) 高密度压缩推理机制用于高效中间计算；3) 答案生成组件将压缩推理转换为人类可读的解决方案

Result: 在多个推理问答基准测试中，Denser相比标准思维链方法减少了高达62%的token消耗，同时保持或提高了准确性，特别是在复杂多步推理问题上效果显著

Conclusion: 通过区分推理和回答阶段的信息密度，Denser框架显著提高了LLM推理效率，为复杂推理任务提供了更高效的解决方案

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [23] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE平台将每日新闻转化为周度决策洞察，为芬兰应用科学大学提供定制化分析。系统爬取新闻、过滤相关性、嵌入内容、PESTEL分类，构建时间依赖递归摘要图，通过轻量级变化检测器突出新增、移除或变更内容，并按主题分组进行PESTEL感知分析。


<details>
  <summary>Details</summary>
Motivation: 为芬兰应用科学大学提供从海量新闻中提取决策相关洞察的自动化解决方案，解决信息过载问题，帮助大学及时了解与自身相关的环境变化，支持课程智能等应用场景。

Method: 1. 新闻爬取与版本管理；2. 大学特定相关性过滤；3. 内容嵌入；4. PESTEL维度分类；5. 构建时间依赖递归摘要图（TRSG）- 两层聚类由LLM总结，每周重新计算；6. 轻量级变化检测器识别新增、移除、变更内容；7. 按主题分组进行PESTEL感知分析。

Result: 开发了稳定生产的ORACLE平台，能够自动将每日新闻转化为周度决策洞察，支持课程智能等具体应用案例，并制定了评估计划。

Conclusion: ORACLE系统成功实现了从新闻到决策洞察的自动化转换，通过精心设计的生产稳定架构，为高等教育机构提供了有效的环境监测和课程智能支持工具。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [24] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 本研究开发并评估了基于大语言模型的动机性访谈系统，通过微调中文开源LLMs，使其能够执行接近真实MI咨询师的核心行为。


<details>
  <summary>Details</summary>
Motivation: 动机性访谈是一种有效的健康行为改变咨询方法，但其推广受到需要高度训练的人类咨询师的限制。本研究旨在探索一种可扩展的替代方案，通过开发基于大语言模型的动机性访谈系统来解决这一瓶颈。

Method: 研究首先整理了五个中文心理咨询语料库，使用GPT-4结合MI提示将高质量数据集转换为2,040个MI风格对话。然后对三个中文开源LLMs进行微调，形成MI-LLMs。评估采用基于轮次的自动指标和专家手动编码（使用MITI编码手册4.2.1）。

Result: 微调显著提高了所有三个模型的BLEU-4和ROUGE分数。手动编码显示MI-LLMs在技术和关系全局评分以及MI一致性比例方面接近真实MI对话水平，但复杂反思和反思-问题比例仍然较低。

Conclusion: MI导向的微调能够赋予通用LLMs核心的MI一致性咨询行为，为AI辅助健康行为改变支持提供了可扩展的途径，但需要在数据规模、复杂MI技能和真实世界干预试验方面进一步研究。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [25] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 该研究首次对孟加拉语在2024年孟加拉国大规模抗议期间进行情感分析，创建了包含2028条标注新闻标题的数据集，使用语言特定模型取得了比多语言模型和传统机器学习方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 情感分析在选举和社交媒体趋势等场景已有研究，但在孟加拉语中关于社会动荡期间情感动态的研究存在显著空白。本研究旨在填补这一空白，分析孟加拉国2024年大规模抗议期间的公众情绪。

Method: 研究收集了主要Facebook新闻门户的2028条标注新闻标题，分为愤怒、希望和绝望三类。使用潜在狄利克雷分配(LDA)识别主题，分析互联网封锁等事件对情感模式的影响。比较了语言特定模型与多语言转换器(mBERT, XLM-RoBERTa)和传统机器学习方法(SVM, 逻辑回归)的性能。

Result: 语言特定模型在情感分析任务上表现最佳，超越了多语言转换器(mBERT: 67%, XLM-RoBERTa: 71%)和传统机器学习方法(SVM和逻辑回归: 均为70%)。LDA识别出政治腐败和公众抗议等主要主题，并揭示了互联网封锁等事件对情感模式的影响。

Conclusion: 语言特定模型在分析政治动荡期间的公众情感方面更有效。研究提供了对危机时期公众情绪的宝贵见解，强调了针对特定语言和文化背景开发模型的重要性。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [26] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: CTKVR提出了一种新的KV缓存检索方案，通过两阶段检索（质心级索引+令牌级细化）来平衡长上下文LLM推理中的效率和准确性，在保持精度损失小于1%的同时实现3-4倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 长上下文LLM应用面临KV缓存内存开销大和延迟高的效率挑战。现有动态KV选择方法存在权衡问题：块级索引因检索不相关KV条目而降低准确性，令牌级索引因低效检索机制导致高延迟。

Method: CTKVR采用质心-令牌两阶段检索策略：1) 利用相邻查询向量在RoPE后高度相似的观察，在预填充阶段预计算轻量级质心进行质心级索引；2) 进行令牌级细化实现精确KV检索。同时通过CPU-GPU协同执行优化索引构建和搜索系统。

Result: 在多个基准测试中，CTKVR在保持精度损失小于1%的情况下实现优异性能。在96K上下文长度下，对Llama-3-8B和Yi-9B模型分别实现3倍和4倍的吞吐量提升，且在不同GPU硬件上表现一致。

Conclusion: CTKVR通过创新的两阶段KV检索方案有效解决了长上下文LLM推理中的效率-准确性权衡问题，为实际应用提供了高效的解决方案。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [27] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 研究提出自动化创建专业词汇表(SWL)的方法，相比传统通用服务列表(GSL)更高效，用更少词汇达到95%语言理解覆盖率


<details>
  <summary>Details</summary>
Motivation: 传统语言学家提出的通用服务列表(GSL)需要语言学专业知识、主观输入和大量时间，研究者希望创建更实用的词汇表来帮助语言学习者

Method: 创建专业词汇表(SWL)，即针对特定语料子集的词汇表，使用模型自动化生成，仅基于客观标准

Result: 使用模型创建的SWL在性能上超越了行业标准(NGSL)，用更少的词汇达到了语言理解所需的95%覆盖率

Conclusion: 通过将SWL过程限制在客观标准，可以实现自动化、规模化，并满足全球语言学习者的个性化需求，比传统GSL更实用

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [28] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 该论文系统研究了汉字分解技术在多词表达感知神经机器翻译中的应用，探讨如何通过汉字分解技术更好地表示中文词汇和字符的原始含义，并有效解决多词表达的翻译挑战。


<details>
  <summary>Details</summary>
Motivation: 多词表达式在自然语言处理任务中带来歧义、习语表达、低频使用和广泛变体等挑战。虽然西方语言（特别是英语）在多词表达式处理方面取得了显著进展，但中文等表意文字语言在这方面仍然落后。现有的子词建模技术（如字节对编码）无法直接应用于汉字这样的表意文字脚本。

Method: 采用系统研究方法，在MWE感知神经机器翻译的背景下研究汉字分解技术。通过实验检验汉字分解技术如何帮助表示中文词汇和字符的原始含义，以及如何有效解决多词表达的翻译挑战。

Result: 论文报告了相关实验结果，但摘要中未提供具体数据。研究重点在于探索汉字分解技术对多词表达翻译的贡献机制。

Conclusion: 汉字分解技术为解决中文多词表达翻译挑战提供了有前景的途径，有助于弥补中文等表意文字语言在多词表达式处理方面相对于西方语言的差距。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [29] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: Bolmo是首个在1B和7B参数规模上具有竞争力的完全开放字节级语言模型家族，通过字节化现有子词级模型实现，性能接近领先的子词级模型，同时在字符理解和编码任务上表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统子词分词存在字符理解不足和固定词汇表带来的效率限制问题，而现有的字节级语言模型主要从头训练，成本高昂。研究旨在开发一种高效方法，将现有子词级模型转换为字节级模型，同时保持竞争力。

Method: 通过"字节化"方法将现有子词级语言模型转换为字节级模型。设计了专门的Bolmo架构，解决了先前字节级架构与子词级模型表达能力不匹配的问题，采用精确蒸馏目标，仅需不到1%的典型预训练token预算即可完成转换。

Result: Bolmo在可比规模下显著优于所有先前的字节级语言模型，在字符理解任务上优于源子词级模型，在某些编码任务上也表现更好，在其他任务上接近原始模型的性能。通过更高的token压缩比训练，Bolmo可以实现与子词级模型竞争性的推理速度。

Conclusion: Bolmo使字节级语言模型成为与子词级模型在实际应用中具有竞争力的实用选择，能够克服子词分词的局限性，同时保持高性能，为字节级语言模型的实际应用开辟了新途径。

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [30] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 研究人员开发了PsyDefConv对话语料库和DMRS Co-Pilot四阶段标注管道，用于测量临床对话中的心理防御机制，标注效率提升22.4%，但当前语言模型在防御识别上仍有很大改进空间。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制是管理痛苦的重要策略，但过度使用会损害心理健康。然而，防御机制复杂且难以可靠测量，特别是在临床对话中。现有方法缺乏标准化的标注工具和数据集。

Method: 1) 构建PsyDefConv语料库：包含200个对话和4709个话语，其中2336个求助者话语标注了防御水平；2) 开发DMRS Co-Pilot四阶段标注管道，提供基于证据的预标注；3) 进行平衡研究评估标注效率；4) 专家评审评估证据质量；5) 使用强语言模型进行零样本和微调基准测试。

Result: 1) 语料库标注一致性Cohen's kappa为0.639；2) Co-Pilot减少平均标注时间22.4%；3) 专家评分：证据质量4.62/7，临床合理性4.44/7，洞察力4.40/7；4) 最佳语言模型宏观F1分数约30%，倾向于过度预测成熟防御；5) 语料分析显示成熟防御最常见，存在情绪特异性偏差。

Conclusion: PsyDefConv语料库和DMRS Co-Pilot为研究语言中的防御功能提供了有价值的资源。虽然当前语言模型在防御识别上仍有很大改进空间，但该工具显著提高了标注效率。研究团队将发布语料库、标注、代码和提示以支持相关研究。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [31] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 论文探讨如何在安全关键的信息处理流程中安全可靠地引入大语言模型，提出通过加权指标组合、上下文敏感的错误严重性定义和置信度阈值来降低风险，并在评估者一致性低时触发人工审查。


<details>
  <summary>Details</summary>
Motivation: 大语言模型越来越多地应用于文本处理流程，有可能替代人力瓶颈，但LLM会犯错且某些处理角色是安全关键的（如术后护理分诊、核设施访问调度更新）。如何在先前由人类执行的关键信息流中安全可靠地引入LLM成为一个重要问题。

Method: 论文主张安全论证应聚焦于从LLM流程评估点获得的证据类型，特别是在使用LLM-as-Judges评估器的框架中。提出采用加权指标组合来降低评估中的错误风险，使用上下文敏感性定义错误严重性，并设计置信度阈值，当评估者间一致性低时触发对关键LaJ判断的人工审查。

Result: 虽然无法从许多自然语言处理任务中获得确定性评估，但通过加权指标组合、上下文敏感的错误严重性定义和置信度阈值设计，可以降低评估中的错误风险，并在评估者一致性低时触发人工审查，从而提高LLM在安全关键应用中的可靠性。

Conclusion: 在安全关键的信息处理流程中引入LLM时，安全论证应聚焦于评估证据的质量而非具体技术框架。通过加权指标、上下文敏感的错误严重性定义和置信度阈值设计，结合人工审查机制，可以提高LLM应用的可靠性和安全性。

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [32] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: 本文对全监督微调(SFT)和参数高效微调(PEFT)方法在问答任务中的表现进行了全面评估，特别关注LoRA的秩配置对性能的影响，发现LoRA在特定秩值下能在推理任务上达到甚至超越SFT的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然参数高效微调方法因其计算效率而被广泛使用，但其配置（如秩）在下游问答任务和泛化能力方面的影响尚未得到充分探索。本研究旨在量化SFT和PEFT之间的权衡，并比较它们在域内和域外适应中的准确性。

Method: 在多个推理和记忆数据集上进行全面评估，进行秩扫描以量化SFT和PEFT之间的权衡。比较PEFT和SFT模型在域内和域外适应中的准确性，分析内部表示的光谱特征和层间注意力结构。

Result: LoRA在特定秩值下能在推理任务上达到竞争性甚至优于SFT的性能。研究揭示了不同的泛化行为和任务特定的遗忘模式。通过光谱特征和注意力结构分析，提供了关于表示漂移和注意力模式结构变化的见解。

Conclusion: LoRA作为一种参数高效微调方法，在特定配置下能够在推理任务上实现与全监督微调相当甚至更好的性能，同时揭示了微调方法在泛化能力和任务适应性方面的不同行为模式。

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [33] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: PPSEBM框架结合能量模型和渐进参数选择，有效解决NLP持续学习中的灾难性遗忘问题


<details>
  <summary>Details</summary>
Motivation: 持续学习面临灾难性遗忘的核心挑战，即模型在学习新任务时遗忘先前获得的知识，这在自然语言处理任务中尤为突出

Method: 提出PPSEBM框架：1) 渐进参数选择为每个新任务分配特定参数；2) 能量模型生成先前任务的代表性伪样本；3) 生成样本指导参数选择过程，增强知识保留能力

Result: 在多个NLP基准测试中，PPSEBM优于最先进的持续学习方法，有效缓解了灾难性遗忘问题

Conclusion: PPSEBM为缓解灾难性遗忘提供了一个有前景且鲁棒的解决方案，通过结合渐进参数选择和能量模型生成，在持续学习场景中实现了更好的知识保留

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [34] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 本文提出了一种通用的激活预言机方法，通过训练LLM直接接受LLM激活作为输入，并用自然语言回答相关问题，在多个下游任务中超越了传统的白盒和黑盒方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型激活理解技术通常使用复杂、专业的方法，而最近提出的LatentQA方法虽然简化了这一过程，但仅限于狭窄的任务设置。本文旨在从通用角度探索这种方法，研究其在分布外设置下的表现以及训练数据多样性对性能的影响。

Method: 采用LatentQA方法训练激活预言机，让LLM能够直接接受LLM激活作为输入，并用自然语言回答关于这些激活的任意问题。研究训练数据多样性对性能的影响，包括添加分类任务和自监督上下文预测任务等额外训练数据集。

Result: 激活预言机能够恢复模型中微调后的信息（如传记知识或恶意倾向），即使这些信息未出现在输入文本中，且模型从未使用过微调模型的激活进行训练。在四个下游任务评估中，即使窄训练的LatentQA模型也能良好泛化，添加额外训练数据集能带来持续改进。最佳激活预言机在所有四个任务上都匹配或超越了先前的白盒基线，在3/4任务上表现最佳。

Conclusion: 通过多样化训练来回答自然语言查询，能够赋予模型一种通用的能力，即用语言表达关于LLM激活的信息。激活预言机方法为理解LLM内部表示提供了一种更简单有效的途径。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [35] [Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning](https://arxiv.org/abs/2512.14709)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 该论文提出将Transformer的自注意力和残差流解释为实现近似向量符号架构（VSA），为语言模型的推理行为提供统一视角，并基于此提出改进架构和训练目标。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型展现出类似推理的行为，但在需要稳定符号操作的任务上仍然脆弱。作者希望通过向量符号架构的视角来统一理解这些现象，解释模型的成功与失败模式。

Method: 将自注意力机制解释为VSA：查询和键定义角色空间，值编码填充物，注意力权重执行软解绑，残差连接实现多个绑定结构的叠加。基于此视角提出VSA启发的架构偏置，包括显式绑定/解绑头和超维内存层，以及促进角色-填充分离和鲁棒叠加的训练目标。

Result: 建立了Transformer内部机制与思维链追踪、基于程序的推理和内存增强工具使用之间的联系，解释了变量混淆和逻辑相关提示不一致等特征性失败模式。提出了测量"VSA相似度"和逻辑组合性的度量标准。

Conclusion: 将注意力视为软向量符号计算为构建更可解释和逻辑可靠推理系统提供了原则性途径，并提出了理论和架构上的开放问题。

Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries and keys define role spaces, values encode fillers, attention weights perform soft unbinding, and residual connections realize superposition of many bound structures. We use this algebraic lens to relate transformer internals to chain-of-thought traces, program-based reasoning, and memory-augmented tool use, and to explain characteristic failure modes such as variable confusion and inconsistency across logically related prompts. Building on this perspective, we propose VSA-inspired architectural biases, including explicit binding/unbinding heads and hyperdimensional memory layers, and training objectives that promote role-filler separation and robust superposition. Finally, we outline metrics for measuring "VSA-likeness" and logical compositionality, and pose theoretical and architectural open problems. Overall, the paper argues that viewing attention as soft vector-symbolic computation offers a principled route toward more interpretable and logically reliable reasoning systems.

</details>


### [36] [GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge](https://arxiv.org/abs/2512.14766)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Jiaoyan Chen,Steffen Staab,Yuan He,Evgeny Kharlamov*

Main category: cs.AI

TL;DR: 该论文针对知识图谱问答中知识图谱不完整的问题，提出了一种构建不完整KG基准的方法，并开发了自适应图推理智能体（GR-Agent）来提升在不完整KG上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱问答基准通常假设知识图谱是完整的，但现实中知识图谱往往不完整，许多事实缺失，需要从现有事实进行推理。现有方法在这种不完整KG场景下表现不佳，突显了其有限的推理能力。

Method: 1. 提出构建不完整知识图谱基准的方法论，移除直接支持的三元组同时保留替代推理路径；2. 开发自适应图推理智能体（GR-Agent），将KGQA形式化为智能体与环境交互，智能体在包含图推理工具的动作空间上操作，并维护潜在支持推理证据的记忆。

Result: 实验表明：1. 使用该方法构建的基准上，现有方法在不完整性下性能持续下降；2. GR-Agent在完整和不完整设置下均优于非训练基线，与基于训练的方法表现相当。

Conclusion: 该工作填补了知识图谱问答评估中不完整知识图谱的空白，提出的GR-Agent通过智能体环境交互框架有效提升了在不完整KG上的推理能力，为更现实的KGQA评估提供了方法论和解决方案。

Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.

</details>


### [37] [IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection](https://arxiv.org/abs/2512.14792)
*Roman Nekrasov,Stefano Fossati,Indika Kumara,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.AI

TL;DR: 该研究通过系统注入结构化配置知识，显著提升了LLM生成Terraform IaC代码的正确率，从27.1%提升到62.6%，但意图对齐方面存在瓶颈，揭示了"正确性-一致性差距"。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在生成正确且意图对齐的基础设施即代码方面成功率较低，特别是在Terraform等IaC工具上。需要研究如何通过结构化知识注入来改善LLM的IaC生成能力。

Method: 1. 增强现有IaC-Eval基准，加入云仿真和自动化错误分析；2. 开发LLM辅助IaC代码生成的错误分类法；3. 实施一系列知识注入技术，从朴素检索增强生成到更复杂的图RAG方法，包括图组件的语义丰富化和资源间依赖关系建模。

Result: 基线LLM性能较差（总体成功率27.1%），注入结构化配置知识后，技术验证成功率提升到75.3%，总体成功率提升到62.6%。但意图对齐方面出现平台期，揭示了"正确性-一致性差距"。

Conclusion: 结构化配置知识注入能显著提高LLM生成IaC代码的技术正确性，但LLM在满足细微用户意图方面仍存在局限，它们可以成为熟练的"编码者"但仍然是有限的"架构师"，需要进一步研究来弥合这一差距。

Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a "Correctness-Congruence Gap" where LLMs can become proficient "coders" but remain limited "architects" in fulfilling nuanced user intent.

</details>


### [38] [AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally](https://arxiv.org/abs/2512.14910)
*Nadine Angela Cantonjos,Arpita Biswas*

Main category: cs.AI

TL;DR: AgroAskAI是一个用于农业气候适应的多智能体推理系统，通过模块化角色架构协调自主智能体，整合实时工具和数据，为农村社区提供可操作的气候适应决策支持。


<details>
  <summary>Details</summary>
Motivation: 农村农业地区面临干旱、强降雨和天气模式变化等气候相关风险的损害。现有系统多为单智能体模型或仅用于静态功能的多智能体框架，缺乏支持动态协作推理和情境感知输出的架构。需要为脆弱农村社区提供适应性的风险管理解决方案和决策支持策略。

Method: 提出AgroAskAI多智能体推理系统，采用模块化、角色专业化的架构，使用责任链方法协调自主智能体，整合实时工具和数据集。系统内置治理机制减少幻觉，支持内部反馈，提供连贯且本地相关的策略，并支持多语言交互。

Result: 实验表明，通过额外工具和提示优化，AgroAskAI在常见农业气候适应查询中能提供更可操作、更接地气、更具包容性的输出。结果突显了智能体AI在农业气候适应中可持续和负责任决策支持的潜力。

Conclusion: AgroAskAI展示了智能体AI在农业气候适应决策支持中的前景，通过多智能体协作推理架构，为脆弱农村社区提供可操作、本地化且包容的气候适应策略，有助于可持续农业发展。

Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.

</details>


### [39] [Agentic AI for Integrated Sensing and Communication: Analysis, Framework, and Case Study](https://arxiv.org/abs/2512.15044)
*Wenwen Xie,Geng Sun,Ruichen Zhang,Xuejie Liu,Yinqiu Liu,Jiacheng Wang,Dusit Niyato,Ping Zhang*

Main category: cs.AI

TL;DR: 本文探讨了智能体AI在集成感知与通信(ISAC)系统中的应用价值与前景，提出了一个新颖的智能体ISAC框架，并通过案例研究验证了其在优化ISAC性能方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着无线环境日益动态和复杂，ISAC系统需要更智能的处理和更自主的操作来保持效率和适应性。智能体AI通过支持动态环境中的连续感知-推理-行动循环，为ISAC系统提供了实现智能、自主和高效运行的可行解决方案。

Method: 1. 全面回顾智能体AI和ISAC系统的关键特性；2. 展示ISAC系统的常见优化方法，突出基于生成式AI的智能体AI的显著优势；3. 提出新颖的智能体ISAC框架，并通过案例研究验证其优越性；4. 阐明基于智能体AI的ISAC系统的未来研究方向。

Result: 提出的智能体ISAC框架在优化ISAC性能方面表现出优越性，案例研究验证了该框架的有效性。基于生成式AI的智能体AI在ISAC系统中展现出显著优势。

Conclusion: 智能体AI为ISAC系统提供了实现智能、自主和高效运行的有效途径，提出的智能体ISAC框架具有优越性能，未来需要进一步探索基于智能体AI的ISAC系统的研究方向。

Abstract: Integrated sensing and communication (ISAC) has emerged as a key development direction in the sixth-generation (6G) era, which provides essential support for the collaborative sensing and communication of future intelligent networks. However, as wireless environments become increasingly dynamic and complex, ISAC systems require more intelligent processing and more autonomous operation to maintain efficiency and adaptability. Meanwhile, agentic artificial intelligence (AI) offers a feasible solution to address these challenges by enabling continuous perception-reasoning-action loops in dynamic environments to support intelligent, autonomous, and efficient operation for ISAC systems. As such, we delve into the application value and prospects of agentic AI in ISAC systems in this work. Firstly, we provide a comprehensive review of agentic AI and ISAC systems to demonstrate their key characteristics. Secondly, we show several common optimization approaches for ISAC systems and highlight the significant advantages of generative artificial intelligence (GenAI)-based agentic AI. Thirdly, we propose a novel agentic ISAC framework and prensent a case study to verify its superiority in optimizing ISAC performance. Finally, we clarify future research directions for agentic AI-based ISAC systems.

</details>


### [40] [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)
*Jinwu Hu,Dongjin Yang,Langyu Bian,Zhiquan Wen,Yufeng Wang,Yaofo Chen,Bin Xiao,Yuanqing Li,Mingkui Tan*

Main category: cs.AI

TL;DR: CogER框架通过动态选择推理策略来平衡LLM推理效率与准确性，受人类分层推理启发，根据查询复杂度自动分配处理策略，在领域内外任务上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理策略主要依赖模型自身的快速或慢速模式（如o1思考），难以平衡不同难度查询的推理效率和准确性，需要更智能的自适应策略选择机制。

Method: 提出CogER框架：1) 评估查询复杂度并分配到预定义层级；2) 将策略选择建模为马尔可夫决策过程，使用强化学习训练CogER-Agent；3) 引入认知工具辅助推理，让LLM在思维链中自主调用外部工具。

Result: CogER在领域内任务上获得至少13%的相对平均精确匹配提升，在领域外任务上获得8%的相对增益，优于最先进的测试时缩放方法。

Conclusion: CogER通过动态策略选择有效平衡了LLM推理的准确性和效率，受人类认知启发的方法在处理不同难度查询时表现出优越性能，为自适应推理系统提供了新思路。

Abstract: Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.

</details>


### [41] [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)
*Mohsen Nafar,Michael Römer,Lin Xie*

Main category: cs.AI

TL;DR: 论文提出了一种基于聚类的变量排序框架，用于提升决策图松弛的质量，通过将变量分区为聚类来减少动态排序启发式的搜索空间，在最大加权独立集问题上显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 离散优化中，松弛决策图通过节点合并提供对偶边界，但其质量严重依赖变量排序和合并决策。动态变量排序启发式虽能收紧边界，但全局评估所有变量会带来计算开销。需要平衡边界紧密度与计算成本。

Method: 提出基于聚类的变量排序框架：1) 将未固定变量分区为聚类；2) 采用两种策略：Cluster-to-Cluster（按聚类顺序处理，使用问题特定的聚合准则如累计顶点权重）和Pick-and-Sort（从每个聚类迭代选择和排序代表性变量）；3) 基于MWISP决策图大小增长的理论分析，提出两种设置聚类数量的策略；4) 将策略嵌入基于决策图的分支定界算法。

Result: 在最大加权独立集问题的基准实例上，提出的方法相比标准动态变量排序基线，持续降低了计算成本。

Conclusion: 基于聚类的变量排序框架有效减少了动态排序启发式的搜索空间，在保持边界质量的同时显著降低了计算开销，为离散优化中决策图编译提供了更高效的变量排序方法。

Abstract: Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these relaxed diagrams, i.e. the tightness of the resulting dual bounds, depends critically on the variable ordering and the merging decisions executed during compilation. While dynamic variable ordering heuristics effectively tighten bounds, they often incur computational overhead when evaluated globally across the entire variable set. To mitigate this trade-off, this work introduces a novel clustering-based framework for variable ordering. Instead of applying dynamic ordering heuristics to the full set of unfixed variables, we first partition variables into clusters. We then leverage this structural decomposition to guide the ordering process, significantly reducing the heuristic's search space. Within this framework, we investigate two distinct strategies: Cluster-to-Cluster, which processes clusters sequentially using problem-specific aggregate criteria (such as cumulative vertex weights in the Maximum Weighted Independent Set Problem (MWISP)), and Pick-and-Sort, which iteratively selects and sorts representative variables from each cluster to balance local diversity with heuristic guidance. Later on, developing some theoretical results on the growth of the size of DDs for MWISP we propose two different policies for setting the number of clusters within the proposed framework. We embed these strategies into a DD-based branch-and-bound algorithm and evaluate them on the MWISP. Across benchmark instances, the proposed methodology consistently reduces computational costs compared to standard dynamic variable ordering baseline.

</details>


### [42] [ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I](https://arxiv.org/abs/2512.15298)
*Seok-Hyun Ga,Chun-Yen Chang*

Main category: cs.AI

TL;DR: 该研究利用2025年韩国高考地球科学I部分，深入分析了GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro等大语言模型的多模态科学推理能力和认知局限性，揭示了模型在感知-认知、计算-概念化等方面的缺陷，为设计"抗AI问题"提供了依据。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI完成作业的现象日益普遍，学术诚信和评估有效性受到威胁。研究旨在分析先进大语言模型在科学推理中的多模态能力和认知局限，为教育评估提供应对AI滥用的解决方案。

Method: 使用2025年韩国高考地球科学I部分作为测试材料，设计三种实验条件：整页输入、单项输入和优化多模态输入，评估GPT-4o、Gemini 2.5 Flash和Gemini 2.5 Pro在不同数据结构下的表现，结合定量和定性分析。

Result: 非结构化输入导致性能显著下降；即使在优化条件下，模型仍表现出基本推理缺陷。定性分析揭示了"感知错误"占主导地位，存在"感知-认知鸿沟"（模型能识别视觉数据但无法解释图示符号意义）、"计算-概念化差异"（能计算但无法应用科学概念）和"过程幻觉"（跳过视觉验证依赖背景知识）。

Conclusion: 通过针对AI的认知弱点（特别是感知与认知之间的鸿沟），教育者可以设计"抗AI问题"来区分真实学生能力与AI生成回答，确保评估公平性，为应对课程作业中未经授权的AI使用提供了可行线索。

Abstract: The rapid development of Generative AI is bringing innovative changes to education and assessment. As the prevalence of students utilizing AI for assignments increases, concerns regarding academic integrity and the validity of assessments are growing. This study utilizes the Earth Science I section of the 2025 Korean College Scholastic Ability Test (CSAT) to deeply analyze the multimodal scientific reasoning capabilities and cognitive limitations of state-of-the-art Large Language Models (LLMs), including GPT-4o, Gemini 2.5 Flash, and Gemini 2.5 Pro. Three experimental conditions (full-page input, individual item input, and optimized multimodal input) were designed to evaluate model performance across different data structures. Quantitative results indicated that unstructured inputs led to significant performance degradation due to segmentation and Optical Character Recognition (OCR) failures. Even under optimized conditions, models exhibited fundamental reasoning flaws. Qualitative analysis revealed that "Perception Errors" were dominant, highlighting a "Perception-Cognition Gap" where models failed to interpret symbolic meanings in schematic diagrams despite recognizing visual data. Furthermore, models demonstrated a "Calculation-Conceptualization Discrepancy," successfully performing calculations while failing to apply the underlying scientific concepts, and "Process Hallucination," where models skipped visual verification in favor of plausible but unfounded background knowledge. Addressing the challenge of unauthorized AI use in coursework, this study provides actionable cues for designing "AI-resistant questions" that target these specific cognitive vulnerabilities. By exploiting AI's weaknesses, such as the gap between perception and cognition, educators can distinguish genuine student competency from AI-generated responses, thereby ensuring assessment fairness.

</details>


### [43] [Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations](https://arxiv.org/abs/2512.15388)
*Reinhard Moratz,Niklas Daute,James Ondieki,Markus Kattenbeck,Mario Krajina,Ioannis Giannopoulos*

Main category: cs.AI

TL;DR: 该论文通过定性空间关系提升大语言模型为行人提供路线指引的能力


<details>
  <summary>Details</summary>
Motivation: 大语言模型在提供行人路线指引方面存在局限性，特别是在空间关系的准确描述上，需要改进其基于定性空间关系提供导航指令的能力

Method: 利用定性空间关系方法来增强大语言模型，使其能够生成更准确、更符合人类认知的行人导航指令

Result: 通过引入定性空间关系，大语言模型在行人路线指引方面的准确性和实用性得到显著提升

Conclusion: 定性空间关系是提升大语言模型行人导航能力的关键技术，为智能导航系统提供了更自然、更准确的方向指引

Abstract: This paper deals with improving the capabilities of Large Language Models (LLM) to provide route instructions for pedestrian wayfinders by means of qualitative spatial relations.

</details>


### [44] [Outer-Learning Framework for Playing Multi-Player Trick-Taking Card Games: A Case Study in Skat](https://arxiv.org/abs/2512.15435)
*Stefan Edelkamp*

Main category: cs.AI

TL;DR: 提出一个通过自对弈AI游戏扩展人类专家游戏数据库的通用框架，提高多玩家纸牌游戏早期决策的预测准确性


<details>
  <summary>Details</summary>
Motivation: 在多玩家纸牌游戏中，早期阶段如叫牌、游戏选择和初始选牌对成功至关重要，但当前计算限制下这些决策主要依赖人类专家游戏的统计信息，需要改进

Method: 开发通用自举外部学习框架，通过自对弈AI游戏生成数百万游戏扩展人类游戏数据库，使用完美特征哈希函数处理压缩表，创建自改进的纸牌游戏引擎

Result: 在Skat游戏中的案例研究表明，该自动化方法可以支持游戏中的各种决策

Conclusion: 通过自对弈AI游戏扩展人类专家游戏数据库的框架能够提高预测准确性，为多玩家纸牌游戏提供持续改进的决策支持系统

Abstract: In multi-player card games such as Skat or Bridge, the early stages of the game, such as bidding, game selection, and initial card selection, are often more critical to the success of the play than refined middle- and end-game play. At the current limits of computation, such early decision-making resorts to using statistical information derived from a large corpus of human expert games. In this paper, we derive and evaluate a general bootstrapping outer-learning framework that improves prediction accuracy by expanding the database of human games with millions of self-playing AI games to generate and merge statistics. We implement perfect feature hash functions to address compacted tables, producing a self-improving card game engine, where newly inferred knowledge is continuously improved during self-learning. The case study in Skat shows that the automated approach can be used to support various decisions in the game.

</details>


### [45] [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)
*Jeongseok Kim,Kangjin Kim*

Main category: cs.AI

TL;DR: 本文提出了一种结合ASP和MILP的集成框架，用于处理城市空中交通中的动态运营需求和模糊重调度请求，提供可解释的自适应调度系统。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通中，由于资源受限，垂直起降机场的高效调度受到广泛关注。现有调度问题通常采用混合整数线性规划，但难以处理动态运营需求和人类模糊的重调度请求。

Method: 采用三值逻辑解释模糊用户意图，结合决策树，提出集成答案集编程和混合整数线性规划的新系统。该框架将MILP用于优化调度，ASP用于透明支持人类输入。

Result: 开发了一个集成框架，能够优化调度同时透明支持人类输入，为城市空中交通提供了可解释、自适应的调度结构。

Conclusion: 提出的ASP-MILP集成系统为城市空中交通调度提供了鲁棒的、可解释的、自适应框架，能够有效处理动态需求和模糊用户请求。

Abstract: Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling problem (RCPSP). In this paper, we show our approach to handle both dynamic operation requirements and vague rescheduling requests from humans. Particularly, we utilize a three-valued logic for interpreting ambiguous user intents and a decision tree, proposing a newly integrated system that combines Answer Set Programming (ASP) and MILP. This integrated framework optimizes schedules and supports human inputs transparently. With this system, we provide a robust structure for explainable, adaptive UAM scheduling.

</details>


### [46] [Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision](https://arxiv.org/abs/2512.15489)
*Wei Du,Shubham Toshniwal,Branislav Kisacanin,Sadegh Mahdavi,Ivan Moshkov,George Armstrong,Stephen Ge,Edgar Minasyan,Feng Chen,Igor Gitman*

Main category: cs.AI

TL;DR: Nemotron-Math是一个包含750万条解题轨迹的大规模数学推理数据集，整合了AoPS竞赛题和StackExchange-Math社区问题，支持三种推理模式和Python工具集成，在多项数学基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据集在推理风格多样性、长形式解题轨迹和工具集成方面存在局限，需要更高质量、更大规模的监督数据来提升数学推理模型的性能。

Method: 利用GPT-OSS-120B的多模式生成能力，创建包含高、中、低三种推理模式的7.5M解题轨迹数据集；整合85K AoPS竞赛题和262K StackExchange-Math社区问题；开发序列分桶策略加速128K上下文长度微调。

Result: Nemotron-Math在匹配的AoPS问题上持续优于原始OpenMathReasoning；加入StackExchange-Math显著提升鲁棒性和泛化能力，特别是在HLE-Math上；在AIME 2024和2025上使用Python TIR达到100% maj@16准确率。

Conclusion: Nemotron-Math数据集通过整合多样化的数学问题和多模式推理轨迹，结合高效的训练策略，实现了数学推理任务的最先进性能，为数学AI研究提供了高质量的大规模监督数据。

Abstract: High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The dataset integrates 85K curated AoPS problems with 262K community-sourced StackExchange-Math problems, combining structured competition tasks with diverse real-world mathematical queries. We conduct controlled evaluations to assess the dataset quality.
  Nemotron-Math consistently outperforms the original OpenMathReasoning on matched AoPS problems. Incorporating StackExchange-Math substantially improves robustness and generalization, especially on HLE-Math, while preserving accuracy on math competition benchmarks.
  To support efficient long-context training, we develop a sequential bucketed strategy that accelerates 128K context-length fine-tuning by 2--3$\times$ without significant accuracy loss. Overall, Nemotron-Math enables state-of-the-art performance, including 100\% maj@16 accuracy on AIME 2024 and 2025 with Python TIR.

</details>


### [47] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song,Jieyu Lu,Yuanqi Du,Botao Yu,Thomas M. Pruyn,Yue Huang,Kehan Guo,Xiuzhe Luo,Yuanhao Qu,Yi Qu,Yinkai Wang,Haorui Wang,Jeff Guo,Jingru Gan,Parshin Shojaee,Di Luo,Andres M Bran,Gen Li,Qiyuan Zhao,Shao-Xiong Lennon Luo,Yuxuan Zhang,Xiang Zou,Wanru Zhao,Yifan F. Zhang,Wucheng Zhang,Shunan Zheng,Saiyang Zhang,Sartaaj Takrim Khan,Mahyar Rajabi-Kochi,Samantha Paradi-Maropakis,Tony Baltoiu,Fengyu Xie,Tianyang Chen,Kexin Huang,Weiliang Luo,Meijing Fang,Xin Yang,Lixue Cheng,Jiajun He,Soha Hassoun,Xiangliang Zhang,Wei Wang,Chandan K. Reddy,Chao Zhang,Zhiling Zheng,Mengdi Wang,Le Cong,Carla P. Gomes,Chang-Yu Hsieh,Aditya Nandy,Philippe Schwaller,Heather J. Kulik,Haojun Jia,Huan Sun,Seyed Mohamad Moosavi,Chenru Duan*

Main category: cs.AI

TL;DR: 论文提出了一个基于场景的科学发现评估框架，用于评估大语言模型在真实科学研究中的能力，发现当前模型在科学发现方面存在系统性弱点，与通用科学基准存在性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有科学基准主要测试去情境化的知识，忽视了驱动科学发现的迭代推理、假设生成和观察解释等关键能力，需要开发更贴近真实科学发现过程的评估框架。

Method: 引入场景驱动的基准，由领域专家定义真实研究项目并分解为模块化研究场景，从这些场景中抽样验证问题。采用两阶段评估框架：问题级准确性评估和项目级性能评估（包括提出可检验假设、设计实验、解释结果等）。

Result: 应用该框架评估最先进的大语言模型发现：1）相对于通用科学基准存在一致性能差距；2）模型规模和推理扩展的收益递减；3）不同提供商顶级模型存在系统性弱点；4）研究场景间性能差异大，导致不同科学发现项目的最佳模型选择变化。

Conclusion: 当前所有大语言模型距离通用科学"超级智能"还很遥远，但已显示出在多种科学发现项目中的潜力。该框架为LLMs的科学发现相关评估提供了可复现的基准，并为推动其面向科学发现的发展指明了实用路径。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


### [48] [A Decision-Theoretic Approach for Managing Misalignment](https://arxiv.org/abs/2512.15584)
*Daniel A. Herrmann,Abinav Chari,Isabelle Qian,Sree Sharvesh,B. A. Levinstein*

Main category: cs.AI

TL;DR: 本文提出了一个决策理论框架，用于在不确定性下确定何时将决策委托给AI系统，强调需要平衡价值对齐、认知准确性和行动范围三个因素。


<details>
  <summary>Details</summary>
Motivation: 现有价值对齐文献主要关注如何塑造AI价值观，但较少研究在不确定性下如何判断不完全对齐是否足以证明委托决策的合理性。需要建立原则性方法来决定AI在特定情境下是否"足够对齐"。

Method: 引入形式化的决策理论框架，精确分析委托决策中的权衡关系，考虑委托者对AI价值对齐、认知准确性和行动范围的不确定性。开发了新的评分框架来量化这种事前决策。

Result: 分析揭示了两种委托场景的明显区别：1）通用委托（信任AI处理任何问题）需要近乎完美的价值对齐和完全的认知信任，实践中很少满足；2）情境特定委托即使在显著价值不对齐的情况下也可能是最优的，因为AI的更高准确性或更广行动范围可能提供更好的整体决策问题。

Conclusion: 本文提供了原则性方法来确定AI在特定情境下是否足够对齐，将重点从实现完美对齐转向在不确定性下管理委托的风险和回报。情境特定委托可以成为理性选择，即使存在显著的价值不对齐。

Abstract: When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.

</details>


### [49] [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)
*Jiaqi Xu,Cuiling Lan,Xuejin Chen,Yan LU*

Main category: cs.AI

TL;DR: STC框架在单个模型内将推理与自我批判交织，通过混合强化学习优化推理质量和自我评估，在数学推理基准上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型将推理与验证分离：要么生成推理而不进行显式自我检查，要么依赖外部验证器事后检测错误。前者缺乏即时反馈，后者增加系统复杂性并阻碍同步学习。受人类批判性思维启发，需要统一框架。

Method: 提出Stepwise Think-Critique (STC)框架，在单个模型内每一步交织推理和自我批判。使用混合强化学习目标训练，结合推理奖励和批判一致性奖励，共同优化推理质量和自我评估。

Result: 在数学推理基准测试中，STC表现出强大的批判性思维能力，并产生更可解释的推理轨迹。

Conclusion: STC代表了向具有内置批判性思维的大语言模型迈出的一步，展示了在单个模型中统一推理和自我评估的潜力。

Abstract: Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.

</details>


### [50] [Explaining the Reasoning of Large Language Models Using Attribution Graphs](https://arxiv.org/abs/2512.15663)
*Chase Walker,Rickard Ewetz*

Main category: cs.AI

TL;DR: CAGE框架通过构建属性图来改进LLM的上下文归因，量化每个生成内容如何受提示和先前生成内容的影响，提高归因忠实度达40%


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然能力强大，但其推理过程不透明，存在安全和信任问题。现有的上下文归因方法不完整，只将生成的token直接关联到提示，忽略了生成过程中的代际影响。

Method: 提出CAGE框架，构建属性图（有向图），量化每个生成内容如何受提示和所有先前生成内容的影响。该图保持因果关系和行随机性，通过沿图中路径边缘化中间贡献来计算上下文归因。

Result: 在多个模型、数据集、指标和方法上，CAGE显著提高了上下文归因的忠实度，平均提升高达40%。

Conclusion: CAGE框架通过考虑生成过程中的代际影响，提供了更完整和忠实的LLM行为解释，解决了现有上下文归因方法的局限性。

Abstract: Large language models (LLMs) exhibit remarkable capabilities, yet their reasoning remains opaque, raising safety and trust concerns. Attribution methods, which assign credit to input features, have proven effective for explaining the decision making of computer vision models. From these, context attributions have emerged as a promising approach for explaining the behavior of autoregressive LLMs. However, current context attributions produce incomplete explanations by directly relating generated tokens to the prompt, discarding inter-generational influence in the process. To overcome these shortcomings, we introduce the Context Attribution via Graph Explanations (CAGE) framework. CAGE introduces an attribution graph: a directed graph that quantifies how each generation is influenced by both the prompt and all prior generations. The graph is constructed to preserve two properties-causality and row stochasticity. The attribution graph allows context attributions to be computed by marginalizing intermediate contributions along paths in the graph. Across multiple models, datasets, metrics, and methods, CAGE improves context attribution faithfulness, achieving average gains of up to 40%.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [51] [Epistemic diversity across language models mitigates knowledge collapse](https://arxiv.org/abs/2512.15011)
*Damian Hodel,Jevin D. West*

Main category: cs.LG

TL;DR: 研究探讨AI生态系统多样性如何缓解知识崩溃问题，发现适度的认知多样性可以减轻性能衰减，但过多或过少都会导致表现下降。


<details>
  <summary>Details</summary>
Motivation: 随着AI的广泛应用，出现了"知识崩溃"的担忧，即知识体系向最主导、最核心的思想集收缩。先前研究已证明单个模型在自身输出上训练会导致性能衰减。受生态学启发，本研究探讨AI生态系统多样性（模型间的多样性）是否能缓解这种崩溃。

Method: 在单模型方法基础上，研究模型生态系统在集体输出上训练的情况。通过将训练数据在不同语言模型间分割，评估由此产生的生态系统在十次自训练迭代中的表现，研究多样性对模型性能的影响。

Result: 研究发现认知多样性的增加确实能缓解崩溃，但只达到一个最优水平。包含太少多样化模型的生态系统无法表达完整真实分布的丰富混合，导致快速性能衰减；而将数据分布在太多模型中会降低每个模型对真实分布的近似能力，导致首次迭代就表现不佳。

Conclusion: 在AI单一文化的背景下，研究结果表明需要监控AI系统间的多样性，并制定政策激励更多领域和社区特定模型的发展。

Abstract: The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.

</details>


### [52] [LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts](https://arxiv.org/abs/2512.14706)
*Krunal Jesani,Dmitry Ignatov,Radu Timofte*

Main category: cs.LG

TL;DR: 本文提出NN-Caption，一个基于大语言模型引导的神经架构搜索管道，通过组合CNN编码器和序列解码器自动生成可运行的图像描述模型，在MS COCO数据集上评估效果。


<details>
  <summary>Details</summary>
Motivation: 传统的神经架构搜索需要大量人工专业知识或自动化试错来设计深度学习模型。本文旨在利用大语言模型来引导神经架构搜索，自动生成图像描述模型，减少人工干预。

Method: 使用DeepSeek-R1-0528-Qwen3-8B作为主要生成器，通过提示模板从LEMUR的分类主干中组合CNN编码器与序列解码器（LSTM/GRU/Transformer），在严格的Net API约束下生成可运行架构。采用基于提示的代码生成与自动评估管道，并处理代码幻觉和API合规性问题。

Result: LLM生成了数十个图像描述模型，其中超过一半成功训练并产生有意义的描述。比较了不同数量输入模型片段（5个vs 10个）的效果，发现提供更多候选组件时成功率略有下降。报告了训练动态和达到的最高BLEU-4分数。

Conclusion: 这项工作展示了LLM引导的NAS的潜力：LLM不仅能提出架构，还能建议超参数和训练实践。通过提示规则和迭代代码修复解决了代码幻觉和API合规性等挑战，为LEMUR数据集添加了数十个新颖的图像描述模型，促进可复现的基准测试和下游AutoML研究。

Abstract: Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEMUR's classification backbones with sequence decoders (LSTM/GRU/Transformer) under a strict Net API. Using DeepSeek-R1-0528-Qwen3-8B as the primary generator, we present the prompt template and examples of generated architectures. We evaluate on MS COCO with BLEU-4. The LLM generated dozens of captioning models, with over half successfully trained and producing meaningful captions. We analyse the outcomes of using different numbers of input model snippets (5 vs. 10) in the prompt, finding a slight drop in success rate when providing more candidate components. We also report training dynamics (caption accuracy vs. epochs) and the highest BLEU-4 attained. Our results highlight the promise of LLM-guided NAS: the LLM not only proposes architectures but also suggests hyperparameters and training practices. We identify the challenges encountered (e.g., code hallucinations or API compliance issues) and detail how prompt rules and iterative code fixes addressed them. This work presents a pipeline that integrates prompt-based code generation with automatic evaluation, and adds dozens of novel captioning models to the open LEMUR dataset to facilitate reproducible benchmarking and downstream AutoML research.

</details>


### [53] [Autonomous Source Knowledge Selection in Multi-Domain Adaptation](https://arxiv.org/abs/2512.14710)
*Keqiuyin Li,Jie Lu,Hua Zuo,Guangquan Zhang*

Main category: cs.LG

TL;DR: AutoS方法通过自主选择源域训练样本和模型，利用密度驱动策略筛选相关源信息，结合预训练多模态模型的伪标签增强模块，提升多域自适应性能。


<details>
  <summary>Details</summary>
Motivation: 多源域自适应中，多个源域常包含冗余或不相关信息，特别是在大规模源域设置下，这些信息会损害迁移性能。需要开发有效策略从大量源域中识别和选择最具可迁移性的知识来解决目标任务。

Method: 提出AutoS方法：1) 采用密度驱动选择策略在训练中选择源样本并确定哪些源模型应贡献于目标预测；2) 基于预训练多模态模型构建伪标签增强模块，减轻目标标签噪声并改进自监督。

Result: 在真实世界数据集上的实验表明所提方法的优越性。

Conclusion: AutoS方法能够自主选择相关源信息和模型，有效提升多域自适应性能，特别是在大规模源域设置下。

Abstract: Unsupervised multi-domain adaptation plays a key role in transfer learning by leveraging acquired rich source information from multiple source domains to solve target task from an unlabeled target domain. However, multiple source domains often contain much redundant or unrelated information which can harm transfer performance, especially when in massive-source domain settings. It is urgent to develop effective strategies for identifying and selecting the most transferable knowledge from massive source domains to address the target task. In this paper, we propose a multi-domain adaptation method named \underline{\textit{Auto}}nomous Source Knowledge \underline{\textit{S}}election (AutoS) to autonomosly select source training samples and models, enabling the prediction of target task using more relevant and transferable source information. The proposed method employs a density-driven selection strategy to choose source samples during training and to determine which source models should contribute to target prediction. Simulteneously, a pseudo-label enhancement module built on a pre-trained multimodal modal is employed to mitigate target label noise and improve self-supervision. Experiments on real-world datasets indicate the superiority of the proposed method.

</details>


### [54] [A Bayesian latent class reinforcement learning framework to capture adaptive, feedback-driven travel behaviour](https://arxiv.org/abs/2512.14713)
*Georges Sfeir,Stephane Hess,Thomas O. Hancock,Filipe Rodrigues,Jamal Amani Rad,Michiel Bliemer,Matthew Beck,Fayyaz Khan*

Main category: cs.LG

TL;DR: 提出了一种潜在类别强化学习模型，用于捕捉旅行决策中的经验形成和个体异质性，通过驾驶模拟器数据识别出三种不同的偏好适应模式。


<details>
  <summary>Details</summary>
Motivation: 许多旅行决策涉及经验形成过程，个体随时间学习自己的偏好，同时旅行者之间存在显著的异质性，包括基础偏好和偏好演化方式。现有模型难以同时捕捉这两个现象。

Method: 提出了潜在类别强化学习模型，通过变分贝叶斯方法估计参数，应用于驾驶模拟器数据集，识别不同类别的个体偏好适应模式。

Result: 识别出三种显著不同的个体类别：第一类显示情境依赖的偏好和情境特定的利用倾向；第二类遵循持续利用策略，不受情境影响；第三类采用探索性策略结合情境特定偏好。

Conclusion: LCRL模型能够有效捕捉旅行决策中的经验形成和个体异质性，为理解不同旅行者群体的偏好适应模式提供了有价值的分析框架。

Abstract: Many travel decisions involve a degree of experience formation, where individuals learn their preferences over time. At the same time, there is extensive scope for heterogeneity across individual travellers, both in their underlying preferences and in how these evolve. The present paper puts forward a Latent Class Reinforcement Learning (LCRL) model that allows analysts to capture both of these phenomena. We apply the model to a driving simulator dataset and estimate the parameters through Variational Bayes. We identify three distinct classes of individuals that differ markedly in how they adapt their preferences: the first displays context-dependent preferences with context-specific exploitative tendencies; the second follows a persistent exploitative strategy regardless of context; and the third engages in an exploratory strategy combined with context-specific preferences.

</details>


### [55] [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)
*Zafaryab Haider,Md Hafizur Rahman,Shane Moeykens,Vijay Devabhaktuni,Prabuddha Chakraborty*

Main category: cs.LG

TL;DR: 本文首次研究了对大型语言模型权重进行比特级扰动如何影响图像描述生成的语义含义，同时保持语法结构完整。提出了BLADE框架，通过梯度敏感性估计定位语义关键比特，揭示比特级变化如何重塑生成式视觉语言模型的高层语义。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明硬件比特翻转可能使transformer在非生成任务中变得脆弱，但这些方法忽略了生成系统的语义和语言维度。本研究旨在探索比特级扰动如何影响LLM生成描述的语义含义，同时保持语法结构，揭示比特级变化如何重塑模型的高层语义输出。

Method: 设计了可微分的故障分析框架BLADE，使用基于梯度的敏感性估计来定位语义关键比特，然后通过描述级别的语义-流畅性目标来优化比特选择。该方法不仅关注比特翻转对分类器的影响，更关注对生成系统语义含义的微妙改变。

Result: 研究发现语义漂移不是随机的，而是可以通过模型自身的梯度进行可微估计。即使难以察觉的低层比特变化也能引导生成式视觉语言模型的高层语义，单个翻转的比特可能微妙地改变视觉特征到词语的映射，从而改变AI对世界的叙述。

Conclusion: 比特级故障分析揭示了语义在比特级别的编码、分布和可改变性，为鲁棒性测试、对抗防御和可解释AI开辟了新途径，展示了结构化比特级故障如何重塑模型的语义输出。

Abstract: Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LLM) used for image captioning can influence the semantic meaning of its generated descriptions while preserving grammatical structure. While prior fault analysis methods have shown that flipping a few bits can crash classifiers or degrade accuracy, these approaches overlook the semantic and linguistic dimensions of generative systems. In image captioning models, a single flipped bit might subtly alter how visual features map to words, shifting the entire narrative an AI tells about the world. We hypothesize that such semantic drifts are not random but differentiably estimable. That is, the model's own gradients can predict which bits, if perturbed, will most strongly influence meaning while leaving syntax and fluency intact. We design a differentiable fault analysis framework, BLADE (Bit-level Fault Analysis via Differentiable Estimation), that uses gradient-based sensitivity estimation to locate semantically critical bits and then refines their selection through a caption-level semantic-fluency objective. Our goal is not merely to corrupt captions, but to understand how meaning itself is encoded, distributed, and alterable at the bit level, revealing that even imperceptible low-level changes can steer the high-level semantics of generative vision-language models. It also opens pathways for robustness testing, adversarial defense, and explainable AI, by exposing how structured bit-level faults can reshape a model's semantic output.

</details>


### [56] [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)
*Ziqian Bi,Danyang Zhang,Junhao Song,Chiung-Yi Tseng*

Main category: cs.LG

TL;DR: GPT-OSS-20B模型在金融NLP任务中达到与更大模型相当的准确率(65.1% vs 66.5%)，同时计算效率显著更高，挑战了模型规模与性能直接相关的传统假设。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在金融服务中的快速应用，需要严格的评估框架来评估其性能、效率和实际适用性，特别是在资源受限的生产环境中。

Method: 对GPT-OSS模型家族与当代LLMs在10个不同的金融NLP任务上进行全面评估，使用120B和20B参数变体，在真实金融数据集(Financial PhraseBank, FiQA-SA, FLARE FINERORD)上进行实验，引入新的效率指标来衡量性能与资源利用之间的权衡。

Result: GPT-OSS-20B模型在准确率上与更大模型相当(65.1% vs 66.5%)，同时计算效率显著更高(198.4 Token Efficiency Score, 159.80 tokens/秒)，在多个任务中表现优于包括Qwen3-235B在内的更大竞争对手。

Conclusion: GPT-OSS的架构创新和训练策略使较小模型能够以显著降低的计算开销实现竞争性性能，为金融应用中可持续且经济高效的LLM部署提供了途径，挑战了模型规模与任务性能直接相关的普遍假设。

Abstract: The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten diverse financial NLP tasks. Through extensive experimentation on 120B and 20B parameter variants of GPT-OSS, we reveal a counterintuitive finding: the smaller GPT-OSS-20B model achieves comparable accuracy (65.1% vs 66.5%) while demonstrating superior computational efficiency with 198.4 Token Efficiency Score and 159.80 tokens per second processing speed [1]. Our evaluation encompasses sentiment analysis, question answering, and entity recognition tasks using real-world financial datasets including Financial PhraseBank, FiQA-SA, and FLARE FINERORD. We introduce novel efficiency metrics that capture the trade-off between model performance and resource utilization, providing critical insights for deployment decisions in production environments. The benchmark reveals that GPT-OSS models consistently outperform larger competitors including Qwen3-235B, challenging the prevailing assumption that model scale directly correlates with task performance [2]. Our findings demonstrate that architectural innovations and training strategies in GPT-OSS enable smaller models to achieve competitive performance with significantly reduced computational overhead, offering a pathway toward sustainable and cost-effective deployment of LLMs in financial applications.

</details>


### [57] [Hybrid Attribution Priors for Explainable and Robust Model Training](https://arxiv.org/abs/2512.14719)
*Zhuoran Zhang,Feng Zhang,Shangyuan Li,Yang Shi,Yuanxing Zhang,Wei Chen,Tengjiao Wang,Kam-Fai Wong*

Main category: cs.LG

TL;DR: 本文提出CAP框架，通过提取类别感知的归因先验，帮助小语言模型在分类任务中学习更细粒度的类别区分特征，提升模型的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前解释引导学习框架中，归因先验的获取存在挑战。现有归因方法虽然能可靠地突出类别相关词元，但往往关注语义相似类别间的共同关键词，这些类别本身在标准训练中就难以区分，导致归因先验缺乏足够的区分性线索，限制了模型区分能力的提升。

Method: 提出Class-Aware Attribution Prior (CAP)框架，引导语言模型捕获细粒度的类别区分特征，生成更显著、更具区分性的归因先验。进一步提出CAP Hybrid，将CAP的先验与现有归因技术的先验结合，形成更全面平衡的监督信号。通过将模型的自归因与这些增强的先验对齐，鼓励学习多样化的决策相关特征。

Result: 在完整数据、少样本和对抗场景下的广泛实验表明，该方法能持续提升模型的可解释性和鲁棒性。

Conclusion: CAP框架通过提取类别感知的归因先验，有效解决了现有归因方法在区分语义相似类别时的局限性，为小语言模型在分类任务中提供了更好的解释引导学习方案。

Abstract: Small language models (SLMs) are widely used in tasks that require low latency and lightweight deployment, particularly classification. As interpretability and robustness gain increasing importance, explanation-guided learning has emerged as an effective framework by introducing attribution-based supervision during training; however, deriving general and reliable attribution priors remains a significant challenge. Through an analysis of representative attribution methods in classification settings, we find that although these methods can reliably highlight class-relevant tokens, they often focus on common keywords shared by semantically similar classes. Because such classes are already difficult to distinguish under standard training, these attributions provide insufficient discriminative cues, limiting their ability to improve model differentiation. To overcome this limitation, we propose Class-Aware Attribution Prior (CAP), a novel attribution prior extraction framework that guides language models toward capturing fine-grained class distinctions and producing more salient, discriminative attribution priors. Building on this idea, we further introduce CAP Hybrid, which combines priors from CAP with those from existing attribution techniques to form a more comprehensive and balanced supervisory signal. By aligning a model's self-attribution with these enriched priors, our approach encourages the learning of diverse, decision-relevant features. Extensive experiments in full-data, few-shot, and adversarial scenarios demonstrate that our method consistently enhances both interpretability and robustness.

</details>


### [58] [Automatic Extraction of Rules for Generating Synthetic Patient Data From Real-World Population Data Using Glioblastoma as an Example](https://arxiv.org/abs/2512.14721)
*Arno Appenzeller,Nick Terzer,André Hohmeyer,Jan-Philipp Redlich,Sabine Luttmann,Friedrich Feuerhake,Nadine S. Schaadt,Timm Intemann,Sarah Teuber-Hanselmann,Stefan Nikolin,Joachim Weis,Klaus Kraywinkel,Pascal Birnstill*

Main category: cs.LG

TL;DR: 本文提出了一种基于癌症报告统计信息自动生成Synthea规则的方法，并以胶质母细胞瘤为例创建了Synthea模块，生成的数据保留了原始统计特性。


<details>
  <summary>Details</summary>
Motivation: 合成数据生成是医疗数据隐私合规二次使用的有前景技术，但创建有意义的Synthea规则需要专家知识和真实样本数据，过程复杂。本文旨在自动化这一过程。

Method: 从癌症报告中提取表格数据统计信息，自动生成Synthea规则。以胶质母细胞瘤真实数据集为例，创建Synthea模块并生成合成数据集。

Result: 生成的合成数据重现了已知疾病病程，大部分保留了原始数据集的统计特性。合成数据可用于假设制定和原型开发。

Conclusion: 合成患者数据在隐私保护研究中具有巨大潜力，但医学解释应考虑当前方法的特定局限性。

Abstract: The generation of synthetic data is a promising technology to make medical data available for secondary use in a privacy-compliant manner. A popular method for creating realistic patient data is the rule-based Synthea data generator. Synthea generates data based on rules describing the lifetime of a synthetic patient. These rules typically express the probability of a condition occurring, such as a disease, depending on factors like age. Since they only contain statistical information, rules usually have no specific data protection requirements. However, creating meaningful rules can be a very complex process that requires expert knowledge and realistic sample data. In this paper, we introduce and evaluate an approach to automatically generate Synthea rules based on statistics from tabular data, which we extracted from cancer reports. As an example use case, we created a Synthea module for glioblastoma from a real-world dataset and used it to generate a synthetic dataset. Compared to the original dataset, the synthetic data reproduced known disease courses and mostly retained the statistical properties. Overall, synthetic patient data holds great potential for privacy-preserving research. The data can be used to formulate hypotheses and to develop prototypes, but medical interpretation should consider the specific limitations as with any currently available approach.

</details>


### [59] [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)
*Mohamed Malhou,Ludovic Perret,Kristin Lauter*

Main category: cs.LG

TL;DR: 本文改进了使用Transformer计算Gröbner基的方法，通过引入分层注意力Transformer（HATs）来求解多元多项式方程组，相比之前的平面注意力模型实现了显著的计算节省。


<details>
  <summary>Details</summary>
Motivation: Kera等人在NeurIPS 2024中首次使用Transformer计算Gröbner基，这是计算机代数中的核心对象，具有众多实际应用。本文旨在改进这一方法，通过引入具有层次结构归纳偏置的Transformer架构来更有效地处理多元多项式方程组。

Method: 采用分层注意力Transformer（HATs）架构，该架构包含树状结构归纳偏置，能够建模数据中的层次关系。方法推广到任意深度，并包含详细的计算成本分析。结合课程学习策略，使模型能够处理比先前工作更大规模的问题实例。

Result: 相比传统的平面注意力模型，HATs架构实现了显著的计算节省。结合课程学习后，该方法能够解决比Kera等人（2024）工作中大得多的实例。

Conclusion: 分层注意力Transformer为计算Gröbner基提供了更高效的架构，通过利用数据中的层次结构关系，在保持准确性的同时大幅降低了计算成本，扩展了可处理问题的规模。

Abstract: At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate polynomial equations via Groebner bases computation. The HAT architecture incorporates a tree-structured inductive bias that enables the modeling of hierarchical relationships present in the data and thus achieves significant computational savings compared to conventional flat attention models. We generalize to arbitrary depths and include a detailed computational cost analysis. Combined with curriculum learning, our method solves instances that are much larger than those in Kera et al. (2024 Learning to compute Groebner bases)

</details>


### [60] [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)
*Klaus-Rudolf Kladny,Bernhard Schölkopf,Lisa Koch,Christian F. Baumgartner,Michael Muehlebach*

Main category: cs.LG

TL;DR: 本文质疑了共形预测在小校准集下统计保证的实际效用，指出虽然理论保证对任意大小的校准集都成立，但实际效用高度依赖校准集大小，这在医疗数据稀缺场景中尤其重要。


<details>
  <summary>Details</summary>
Motivation: 机器学习在医疗领域的应用需要可靠的置信度估计，但标准ML模型无法提供。共形预测(CP)可以将启发式置信度估计转化为具有统计保证的置信度估计。虽然CP理论声称对任意大小的校准集都成立，但作者质疑这种承诺在小校准集下的实际效用。

Method: 作者通过理论分析和实证研究，探讨了校准集大小对共形预测实际效用的影响。在医疗图像分类任务上进行了实证验证，展示了小校准集下统计保证的实际局限性。

Result: 研究发现，虽然共形预测的统计保证在理论上对任意大小的校准集都成立，但这些保证的实际效用高度依赖校准集的大小。小校准集会导致预测集过大或置信度估计不准确，从而降低实际应用价值。

Conclusion: 在医疗等数据稀缺领域应用共形预测时，需要谨慎考虑校准集大小对实际效用的影响。单纯依赖理论统计保证可能不足以支持临床决策，需要更全面的评估方法。

Abstract: Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistical guarantees. CP works by converting predictions of a ML model, together with a calibration sample, into prediction sets that are guaranteed to contain the true label with any desired probability. An often cited advantage is that CP theory holds for calibration samples of arbitrary size, suggesting that uncertainty estimates with practically meaningful statistical guarantees can be achieved even if only small calibration sets are available. We question this promise by showing that, although the statistical guarantees hold for calibration sets of arbitrary size, the practical utility of these guarantees does highly depend on the size of the calibration set. This observation is relevant in medical domains because data is often scarce and obtaining large calibration sets is therefore infeasible. We corroborate our critique in an empirical demonstration on a medical image classification task.

</details>


### [61] [A data-driven approach to inferring travel trajectory during peak hours in urban rail transit systems](https://arxiv.org/abs/2512.14728)
*Jie He,Yong Qin,Jianyuan Guo,Xuan Sun,Xuanchuan Zheng*

Main category: cs.LG

TL;DR: 本文提出了一种基于AFC和AVL数据的城市轨道交通个体出行轨迹推断方法，通过KLEM算法实现数据驱动的参数估计，无需外部调查数据，在高峰时段达到90%以上的轨迹推断准确率。


<details>
  <summary>Details</summary>
Motivation: 城市轨道交通精细化轨迹推断对运营组织具有重要意义。现有方法依赖外部调查数据或合成数据验证，缺乏鲁棒性和适用性。

Method: 1. 基于时空约束建立列车备选集；2. 提出基于KL散度结合EM算法的KLEM参数估计方法，实现数据驱动的自适应轨迹推断；3. 构建完整出行轨迹；4. 使用真实个体出行轨迹数据进行验证。

Result: 该方法在城市轨道交通高峰时段的出行轨迹推断准确率超过90%，实现了高精度的乘客轨迹推断。

Conclusion: 提出的数据驱动方法消除了对外部调查数据的依赖，增强了模型的鲁棒性和适用性，能够实现高精度的城市轨道交通个体出行轨迹推断。

Abstract: Refined trajectory inference of urban rail transit is of great significance to the operation organization. In this paper, we develop a fully data-driven approach to inferring individual travel trajectories in urban rail transit systems. It utilizes data from the Automatic Fare Collection (AFC) and Automatic Vehicle Location (AVL) systems to infer key trajectory elements, such as selected train, access/egress time, and transfer time. The approach includes establishing train alternative sets based on spatio-temporal constraints, data-driven adaptive trajectory inference, and trave l trajectory construction. To realize data-driven adaptive trajectory inference, a data-driven parameter estimation method based on KL divergence combined with EM algorithm (KLEM) was proposed. This method eliminates the reliance on external or survey data for parameter fitting, enhancing the robustness and applicability of the model. Furthermore, to overcome the limitations of using synthetic data to validate the result, this paper employs real individual travel trajectory data for verification. The results show that the approach developed in this paper can achieve high-precision passenger trajectory inference, with an accuracy rate of over 90% in urban rail transit travel trajectory inference during peak hours.

</details>


### [62] [Semantic Geometry for policy-constrained interpretation](https://arxiv.org/abs/2512.14731)
*Nikit Phadke*

Main category: cs.LG

TL;DR: 提出了一种几何框架，通过球面凸区域表示语义，将证据与策略约束分离，确保高风险领域中零幻觉承诺


<details>
  <summary>Details</summary>
Motivation: 解决高风险领域（如金融监管）中语义解释可能产生幻觉承诺的问题，需要一种能够严格防止错误批准的理论框架

Method: 将语义表示为单位球面上的方向，证据建模为见证向量集合，可接受解释对应球面凸区域，策略约束作为显式先验引入，通过约束优化进行解释

Result: 在大规模受监管金融数据上实现零幻觉批准，证明复杂度边界在信息论上是最优的

Conclusion: 该几何框架为高风险领域的语义解释提供了理论保证，能够严格防止幻觉承诺，拒绝机制在矛盾或策略排除时成为拓扑必然结果

Abstract: We present a geometric framework for policy-constrained semantic interpretation that provably prevents hallucinated commitments in high-stakes domains. Semantic meaning is represented as direction on a unit sphere, evidence is modeled as sets of witness vectors, and admissible interpretations correspond to spherical convex regions. Policy constraints are introduced as explicit priors defined over the same manifold, separated from evidence geometry. Interpretation reduces to constrained optimization over admissible regions, with refusal emerging as a topologically necessary outcome under contradiction or policy exclusion. We connect this framework to information theory, Bayesian inference, and sheaf-theoretic semantics, proving that our complexity bounds are information-theoretically optimal. Empirical validation on large scale regulated financial data demonstrates zero hallucinated approvals across multiple policy regimes-the first such result at scale.

</details>


### [63] [Inference Time Feature Injection: A Lightweight Approach for Real-Time Recommendation Freshness](https://arxiv.org/abs/2512.14734)
*Qiang Chen,Venkatesh Ganapati Hegde,Hongfei Li*

Main category: cs.LG

TL;DR: 提出了一种轻量级、模型无关的日内个性化方法，通过推理时选择性注入近期观看历史来更新用户特征，无需重新训练模型，显著提升了长视频流媒体服务的用户参与度。


<details>
  <summary>Details</summary>
Motivation: 当前长视频流媒体推荐系统通常依赖批量训练的模型和每日更新的特征，这种方法虽然高效但无法捕捉用户的最新行为，导致推荐内容过时，无法实时适应用户偏好变化。

Method: 开发了一种轻量级、模型无关的日内个性化方法，在推理时选择性覆盖过时的用户特征，使用近期观看历史来更新用户表示，无需重新训练模型，实现了从每日到日内级别的个性化反馈循环。

Result: 通过将个性化反馈循环从每日缩短到日内，观察到关键用户参与度指标实现了统计显著的0.47%增长，这是近期实验周期中观察到的最显著的参与度提升之一。

Conclusion: 这是首个证明日内个性化能在长视频流媒体服务中产生有意义影响的公开证据，为需要模型重新训练的完整实时架构提供了一个有吸引力的替代方案。

Abstract: Many recommender systems in long-form video streaming reply on batch-trained models and batch-updated features, where user features are updated daily and served statically throughout the day. While efficient, this approach fails to incorporate a user's most recent actions, often resulting in stale recommendations. In this work, we present a lightweight, model-agnostic approach for intra-day personalization that selectively injects recent watch history at inference time without requiring model retraining. Our approach selectively overrides stale user features at inference time using the recent watch history, allowing the system to adapt instantly to evolving preferences. By reducing the personalization feedback loop from daily to intra-day, we observed a statistically significant 0.47% increase in key user engagement metrics which ranked among the most substantial engagement gains observed in recent experimentation cycles. To our knowledge, this is the first published evidence that intra-day personalization can drive meaningful impact in long-form video streaming service, providing a compelling alternative to full real-time architectures where model retraining is required.

</details>


### [64] [NoveltyRank: Estimating Conceptual Novelty of AI Papers](https://arxiv.org/abs/2512.14738)
*Zhengxu Yan,Han Li,Yuming Feng*

Main category: cs.LG

TL;DR: 开发了一个评估AI论文概念新颖性的模型，通过标题、摘要和与先前文献的语义相似性来量化研究原创性，帮助研究人员和审稿人识别真正创新的工作。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版门槛降低，AI领域论文数量激增，真正有创新性的工作难以脱颖而出，而人工评估新颖性不稳定且耗时。需要一种数据驱动、可扩展的方法来评估研究原创性。

Method: 通过论文标题、摘要和与先前文献的语义相似性评估新颖性。探索了两种任务形式：1）二元分类，从先前新颖工作中学习模式预测绝对新颖性；2）成对新颖性比较，学习区分论文的相对新颖性。使用Qwen3-4B-Instruct-2507和SciBERT进行微调，并与GPT-5.1进行基准测试。

Result: 开发了名为NoveltyRank的公开可用系统，实现了两种新颖性评估方法，分析了任务形式和建模选择对性能的影响，为研究新颖性评估提供了量化工具。

Conclusion: 该研究为AI论文新颖性评估提供了数据驱动的解决方案，能够帮助研究人员高效识别真正创新的工作，为会议审稿人提供一致的新颖性量化信号，促进学术创新。

Abstract: With the growing ease of academic publishing, the volume of research papers, especially in AI-related fields, has surged dramatically. This flood of publications makes it difficult for truly novel and impactful work to stand out, and manual novelty assessment is often unstable and time-consuming. Our project aims to develop a model that estimates and ranks the conceptual novelty of AI papers, enabling a data-driven and scalable assessment of research originality. Such a system can help researchers efficiently identify submissions that introduce genuinely innovative ideas rather than minor variants, and provide conference reviewers with a quantitative and consistent signal of novelty. Our approach evaluates novelty primarily through a paper's title, abstract, and semantic similarity to prior literature. Given the motivation of novelty estimation, we explore two task formulations with different modeling objectives, each offering a different perspective: (1) binary classification, which predicts the paper's absolute novelty from learned patterns of prior novel works, and (2) pairwise novelty comparison, which learns to distinguish papers by relative novelty over others. We fine-tune Qwen3-4B-Instruct-2507 and SciBERT on both tasks, benchmarking against GPT-5.1 to analyze how task formulation and modeling choices affect performance. The implementation is publicly available at https://github.com/ZhengxuYan/NoveltyRank.

</details>


### [65] [Guided Discrete Diffusion for Constraint Satisfaction Problems](https://arxiv.org/abs/2512.14765)
*Justin Jung*

Main category: cs.LG

TL;DR: 提出离散扩散引导方法解决约束满足问题，以数独为例展示无监督学习能力


<details>
  <summary>Details</summary>
Motivation: 约束满足问题（CSPs）在人工智能中具有重要应用，但传统方法通常需要监督学习或复杂的启发式规则。研究者希望开发一种无需监督的方法来解决这类问题，特别是像数独这样的经典CSP。

Method: 采用离散扩散引导技术，该方法通过扩散过程在离散状态空间中进行采样和优化，引导搜索过程满足约束条件，无需依赖标注数据或预定义规则。

Result: 该方法成功解决了数独难题，展示了在无监督条件下解决约束满足问题的有效性，为CSP求解提供了新的技术路径。

Conclusion: 离散扩散引导为约束满足问题提供了一种有前景的无监督求解方法，特别适用于缺乏标注数据或复杂规则难以形式化的场景，具有扩展到其他CSP问题的潜力。

Abstract: We propose discrete diffusion guidance for constraint satisfaction problems (CSPs) and demonstrate its ability to solve Sudoku puzzles without supervision.

</details>


### [66] [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)
*Kornelius Raeth,Nicole Ludwig*

Main category: cs.LG

TL;DR: 论文提出决策校准框架，从决策者角度而非预报者角度评估天气预报价值，发现预报层面的性能差异不一定转化为决策层面的优势


<details>
  <summary>Details</summary>
Motivation: 传统天气预报评估主要从预报者角度进行统计比较，但实际应用中预报用于决策制定，需要从决策者角度评估预报对决策质量的提升价值

Method: 提出决策校准框架，在决策层面而非预报层面评估预报性能，比较机器学习模型和经典数值天气预报模型在各种天气依赖决策任务中的表现

Result: 模型在预报层面的性能不能可靠地转化为下游决策性能：一些性能差异只在决策层面显现，不同决策任务中模型排名会发生变化

Conclusion: 典型的预报评估方法不足以为特定决策任务选择最优预报模型，需要采用决策层面的评估框架

Abstract: Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forecast by its ability to improve decision-making. Decision calibration provides a novel framework for evaluating forecast performance at the decision level rather than the forecast level. We evaluate decision calibration to compare Machine Learning and classical numerical weather prediction models on various weather-dependent decision tasks. We find that model performance at the forecast level does not reliably translate to performance in downstream decision-making: some performance differences only become apparent at the decision level, and model rankings can change among different decision tasks. Our results confirm that typical forecast evaluations are insufficient for selecting the optimal forecast model for a specific decision task.

</details>


### [67] [Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse](https://arxiv.org/abs/2512.14879)
*Jingwei Chen*

Main category: cs.LG

TL;DR: ERBP框架统一解释自指学习中的模型崩溃现象，提出熵储层概念来稳定训练过程


<details>
  <summary>Details</summary>
Motivation: 自指学习（模型在自身生成的数据上训练）虽然具有无限扩展潜力，但普遍存在模型崩溃问题。尽管实践中采用各种临时修复方法，但缺乏统一的原理来解释失败模式和修复方法的成功。

Method: 提出熵储层Bregman投影（ERBP）框架，将闭环训练建模为分布空间中的随机Bregman投影序列。通过引入熵储层（高熵分布）注入可控的熵通量来稳定动力学。

Result: 理论推导出：(1) 崩溃的必要条件；(2) 保证非平凡熵底限的充分条件；(3) 仅依赖于样本量和Bregman生成器常数的闭式收敛率。在语言模型自训练、强化学习和GAN优化中验证了预测。

Conclusion: ERBP将各种经验性稳定启发式方法统一为单一量化设计规则：监控和预算熵通量，为自指学习提供了理论框架和实用指导。

Abstract: Self-referential learning -- training a model on data it generated itself -- promises boundless scalability but chronically suffers from model collapse: language models degenerate into repetitive text, GANs drop modes, and reinforcement-learning policies over-exploit. Although practitioners employ ad~hoc fixes such as real-data mixing, entropy bonuses, knowledge distillation, or retrieval-augmented generation, a single principle that explains both the failure mode and the success of these fixes has remained elusive. We present Entropy-Reservoir Bregman Projection (ERBP), an information-geometric framework that unifies these phenomena. We model the closed loop as a stochastic Bregman projection sequence in distribution space. Without external coupling, finite-sample noise forces the system to project onto an ever-shrinking empirical support, causing exponential entropy decay and eventual collapse. Introducing an Entropy Reservoir -- a high-entropy distribution mixed into each projection -- injects a controllable entropy flux that provably stabilises the dynamics. Our theory yields (i) a necessary condition for collapse, (ii) a sufficient condition that guarantees a non-trivial entropy floor, and (iii) closed-form rates that depend only on sample size and the strong-convexity/Lipschitz constants of the Bregman generator. Experiments on large-language-model self-training, Soft Actor-Critic in reinforcement learning, and GAN optimisation validate our predictions and show that disparate stabilisation heuristics correspond to specific reservoir choices and coupling coefficients. ERBP thus transforms a collection of folk remedies into a single, quantitative design rule: monitor and budget your entropy flux.

</details>


### [68] [Task Matrices: Linear Maps for Cross-Model Finetuning Transfer](https://arxiv.org/abs/2512.14880)
*Darrin O' Brien,Dhikshith Gajulapalli,Eric Xia*

Main category: cs.LG

TL;DR: 该研究提出了"任务矩阵"概念，证明在视觉和文本模型中存在从基础模型到微调模型的线性编码，通过任务矩阵增强的基础模型性能超越线性探针，有时接近微调水平。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明，在上下文提示偏置下，大型视觉和语言模型学习隐式线性编码，但在更一般的适应机制中是否存在类似线性表示尚未得到验证。本研究旨在探索在通用适应机制中是否存在类似的线性编码表示。

Method: 提出"任务矩阵"概念，即从基础模型嵌入状态到微调模型嵌入状态的线性变换。在视觉和文本模型以及十个不同数据集上进行实验，使用基于数据的近似方法来高效计算这种编码。

Result: 基础模型通过任务矩阵增强后，性能超越线性探针，有时接近微调模型的水平。验证了预训练和微调架构之间存在跨层线性编码，且基于数据的近似方法既高效又可泛化到多个领域。

Conclusion: 研究证实了在通用适应机制中存在线性编码表示，任务矩阵提供了一种高效且可泛化的方法来实现模型适应，为模型解释和高效适应提供了新视角。

Abstract: Results in interpretability suggest that large vision and language models learn implicit linear encodings when models are biased by in-context prompting. However, the existence of similar linear representations in more general adaptation regimes has not yet been demonstrated. In this work, we develop the concept of a task matrix, a linear transformation from a base to finetuned embedding state. We demonstrate that for vision and text models and ten different datasets, a base model augmented with a task matrix achieves results surpassing linear probes, sometimes approaching finetuned levels. Our results validate the existence of cross-layer linear encodings between pretrained and finetuned architectures. Moreover, we show that a data-based approximation for such encodings is both efficient and generalizable to multiple domains. We make our implementation publicly available.

</details>


### [69] [OLR-WA: Online Weighted Average Linear Regression in Multivariate Data Streams](https://arxiv.org/abs/2512.14892)
*Mohammad Abu-Shaira,Alejandro Rodriguez,Greg Speegle,Victor Sheng,Ishfaq Ahmad*

Main category: cs.LG

TL;DR: OLR-WA是一种新颖的多变量在线线性回归模型，通过加权平均方法实现，能够在数据流中增量更新模型，避免大规模存储和重新计算，同时有效处理数据漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在线学习需要增量更新模型以避免大规模存储和计算成本，同时现有在线回归模型在处理数据漂移和置信度场景方面存在局限性，需要一种更通用且性能优越的解决方案。

Method: 提出OLR-WA（在线回归加权平均）模型，采用加权平均方法进行多变量在线线性回归。模型采用保守更新策略，优先考虑置信度较高的旧数据点，能够有效处理时间漂移和置信度挑战场景。

Result: OLR-WA性能与批量回归相当，优于其他最先进的在线模型。在收敛速度方面表现卓越，即使仅用1%-10%的数据初始化，也能从第一次迭代到最后一次迭代保持高r2值。是唯一能有效处理置信度挑战场景的模型。

Conclusion: OLR-WA证明了其在不同场景下的多功能性和实用性，是在线线性回归任务的有价值解决方案，特别在处理数据漂移和置信度场景方面具有独特优势。

Abstract: Online learning updates models incrementally with new data, avoiding large storage requirements and costly model recalculations. In this paper, we introduce "OLR-WA; OnLine Regression with Weighted Average", a novel and versatile multivariate online linear regression model. We also investigate scenarios involving drift, where the underlying patterns in the data evolve over time, conduct convergence analysis, and compare our approach with existing online regression models. The results of OLR-WA demonstrate its ability to achieve performance comparable to the batch regression, while also showcasing comparable or superior performance when compared with other state-of-the-art online models, thus establishing its effectiveness. Moreover, OLR-WA exhibits exceptional performance in terms of rapid convergence, surpassing other online models with consistently achieving high r2 values as a performance measure from the first iteration to the last iteration, even when initialized with minimal amount of data points, as little as 1% to 10% of the total data points. In addition to its ability to handle time-based (temporal drift) scenarios, remarkably, OLR-WA stands out as the only model capable of effectively managing confidence-based challenging scenarios. It achieves this by adopting a conservative approach in its updates, giving priority to older data points with higher confidence levels. In summary, OLR-WA's performance further solidifies its versatility and utility across different contexts, making it a valuable solution for online linear regression tasks.

</details>


### [70] [Low-rank MMSE filters, Kronecker-product representation, and regularization: a new perspective](https://arxiv.org/abs/2512.14932)
*Daniel Gomes de Pinho Zanco,Leszek Szczecinski,Jacob Benesty,Eduardo Vinicius Kuhn*

Main category: cs.LG

TL;DR: 提出了一种基于Kronecker积表示的低秩MMSE滤波器正则化参数高效选择方法，该方法与秩选择问题相关，在低秩设置中至关重要。


<details>
  <summary>Details</summary>
Motivation: 在低秩MMSE滤波器设计中，正则化参数的选择对性能至关重要，但现有方法效率不高。作者发现正则化参数与秩选择问题存在意外联系，需要开发更有效的选择方法。

Method: 基于Kronecker积表示的低秩MMSE滤波器框架，提出了一种高效的正则化参数选择方法。该方法利用了正则化参数与秩选择问题之间的理论联系。

Result: 通过仿真验证，提出的方法相比常用方法取得了显著性能提升，证明了该方法的有效性。

Conclusion: 正则化参数选择在低秩MMSE滤波器中至关重要，提出的基于Kronecker积表示的高效选择方法能够显著提升性能，且该方法与秩选择问题存在理论联系。

Abstract: In this work, we propose a method to efficiently find the regularization parameter for low-rank MMSE filters based on a Kronecker-product representation. We show that the regularization parameter is surprisingly linked to the problem of rank selection and, thus, properly choosing it, is crucial for low-rank settings. The proposed method is validated through simulations, showing significant gains over commonly used methods.

</details>


### [71] [Softly Constrained Denoisers for Diffusion Models](https://arxiv.org/abs/2512.14980)
*Victor M. Yeom Song,Severi Rissanen,Arno Solin,Samuel Kaski,Mingfei Sun*

Main category: cs.LG

TL;DR: 提出一种软约束去噪器方法，将约束知识整合到去噪器本身，而不是修改损失函数或采样循环，以在保持数据分布真实性的同时提高约束合规性


<details>
  <summary>Details</summary>
Motivation: 扩散模型在科学应用中难以生成满足约束条件的样本，现有方法通过损失函数正则化或采样引导会偏离真实数据分布，特别是在约束条件被错误指定时问题更严重

Method: 将引导式调整整合到去噪器本身，赋予其软归纳偏置，使其倾向于生成符合约束的样本，同时保持足够的灵活性以在约束与观测数据不匹配时偏离约束

Result: 软约束去噪器利用约束知识提高了标准去噪器的合规性，同时在约束错误指定时能够保持足够的灵活性偏离约束

Conclusion: 通过将约束知识整合到去噪器本身而不是修改损失或采样过程，可以在保持数据分布真实性的同时有效处理约束条件，特别是在约束可能被错误指定的科学应用场景中

Abstract: Diffusion models struggle to produce samples that respect constraints, a common requirement in scientific applications. Recent approaches have introduced regularization terms in the loss or guidance methods during sampling to enforce such constraints, but they bias the generative model away from the true data distribution. This is a problem, especially when the constraint is misspecified, a common issue when formulating constraints on scientific data. In this paper, instead of changing the loss or the sampling loop, we integrate a guidance-inspired adjustment into the denoiser itself, giving it a soft inductive bias towards constraint-compliant samples. We show that these softly constrained denoisers exploit constraint knowledge to improve compliance over standard denoisers, and maintain enough flexibility to deviate from it when there is misspecification with observed data.

</details>


### [72] [Prompt Repetition Improves Non-Reasoning LLMs](https://arxiv.org/abs/2512.14982)
*Yaniv Leviathan,Matan Kalman,Yossi Matias*

Main category: cs.LG

TL;DR: 重复输入提示能提升主流模型性能，无需增加生成token或延迟


<details>
  <summary>Details</summary>
Motivation: 探索在不使用推理的情况下，如何通过简单方法提升主流语言模型的性能表现

Method: 通过重复输入提示（prompt repetition）的方法，在不增加生成token数量和延迟的情况下测试模型性能

Result: 对于Gemini、GPT、Claude和Deepseek等主流模型，重复输入提示能有效提升性能

Conclusion: 简单的提示重复策略可以在不增加计算成本的情况下提升模型性能，这为优化模型使用提供了实用方法

Abstract: When not using reasoning, repeating the input prompt improves performance for popular models (Gemini, GPT, Claude, and Deepseek) without increasing the number of generated tokens or latency.

</details>


### [73] [Adaptive Partitioning and Learning for Stochastic Control of Diffusion Processes](https://arxiv.org/abs/2512.14991)
*Hanqing Jin,Renyuan Xu,Yanzhao Yang*

Main category: cs.LG

TL;DR: 提出一种用于无界连续状态空间扩散过程的自适应分区强化学习算法，通过动态调整状态-动作空间划分来平衡探索与近似，适用于金融、经济等领域的高维问题。


<details>
  <summary>Details</summary>
Motivation: 解决金融、经济和运筹学中常见的无界连续状态空间、有界连续动作和多项式增长奖励的扩散过程强化学习问题，克服连续高维领域的挑战。

Method: 提出基于模型的自适应分区算法，在状态-动作空间内维护漂移、波动率和奖励的估计器，当估计偏差超过统计置信度时细化离散化分区，平衡探索与近似。

Result: 建立了依赖于问题时间范围、状态维度、奖励增长阶数和针对无界扩散过程新定义的"缩放维度"的遗憾界限，将现有有界设置结果作为特例，并扩展到更广泛的扩散类型问题。

Conclusion: 该自适应分区方法能有效处理无界连续状态空间的扩散过程强化学习问题，通过数值实验验证了其有效性，包括在多资产均值-方差投资组合选择等高维问题中的应用。

Abstract: We study reinforcement learning for controlled diffusion processes with unbounded continuous state spaces, bounded continuous actions, and polynomially growing rewards: settings that arise naturally in finance, economics, and operations research. To overcome the challenges of continuous and high-dimensional domains, we introduce a model-based algorithm that adaptively partitions the joint state-action space. The algorithm maintains estimators of drift, volatility, and rewards within each partition, refining the discretization whenever estimation bias exceeds statistical confidence. This adaptive scheme balances exploration and approximation, enabling efficient learning in unbounded domains. Our analysis establishes regret bounds that depend on the problem horizon, state dimension, reward growth order, and a newly defined notion of zooming dimension tailored to unbounded diffusion processes. The bounds recover existing results for bounded settings as a special case, while extending theoretical guarantees to a broader class of diffusion-type problems. Finally, we validate the effectiveness of our approach through numerical experiments, including applications to high-dimensional problems such as multi-asset mean-variance portfolio selection.

</details>


### [74] [DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding](https://arxiv.org/abs/2512.15000)
*Ruiyi Zhang,Peijia Qin,Qi Cao,Pengtao Xie*

Main category: cs.LG

TL;DR: DreamPRM-Code提出了一种针对代码任务的流程奖励模型，通过函数链提示策略将函数作为推理步骤，并使用元学习校正机制处理标签噪声，在LiveCodeBench上实现了80.9%的pass@1率。


<details>
  <summary>Details</summary>
Motivation: 现有流程奖励模型在代码任务中效果有限，主要因为代码缺乏有意义的步骤分解，以及蒙特卡洛生成的中间标签存在噪声问题。

Method: 1. 使用Chain-of-Function提示策略，将函数作为推理步骤，实现模块化代码生成；2. 引入基于元学习的校正机制，利用干净的最终解决方案单元测试标签，通过双层优化来精炼中间标签。

Result: 在LiveCodeBench上实现了80.9%的pass@1率，超越了OpenAI o4-mini，达到了最先进的性能水平。

Conclusion: DreamPRM-Code通过创新的函数链策略和标签校正机制，有效解决了代码任务中流程奖励模型的关键挑战，显著提升了代码生成的性能。

Abstract: Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.

</details>


### [75] [Stock Pattern Assistant (SPA): A Deterministic and Explainable Framework for Structural Price Run Extraction and Event Correlation in Equity Markets](https://arxiv.org/abs/2512.15008)
*Sandeep Neela*

Main category: cs.LG

TL;DR: SPA是一个确定性的框架，用于从股票价格数据中提取单调价格走势，关联公开事件，并生成事实性解释，旨在提供透明、可审计的历史价格结构分析。


<details>
  <summary>Details</summary>
Motivation: 现有技术指标和预测模型缺乏透明度和可解释性，在需要审计和透明度的场景中存在挑战。需要一种能够提供清晰、可解释历史价格结构分析的工具。

Method: SPA框架使用每日OHLCV数据和标准化事件流，通过确定性方法提取单调价格走势，使用对称相关窗口关联公开事件，并生成受约束的事实性历史解释。

Result: 在AAPL、NVDA、SCHW、PGR四只股票上的评估显示，SPA能够稳定地生成结构分解和上下文叙事，消融实验证明了确定性分割、事件对齐和约束解释对可解释性的贡献。

Conclusion: SPA不是预测系统或交易信号生成器，其价值在于提供透明、可复现的历史价格结构视图，可补充分析师工作流程、风险评估和可解释AI管道。

Abstract: Understanding how prices evolve over time often requires peeling back the layers of market noise to identify clear, structural behavior. Many of the tools commonly used for this purpose technical indicators, chart heuristics, or even sophisticated predictive models leave important questions unanswered. Technical indicators depend on platform-specific rules, and predictive systems typically offer little in terms of explanation. In settings that demand transparency or auditability, this poses a significant challenge. We introduce the Stock Pattern Assistant (SPA), a deterministic framework designed to extract monotonic price runs, attach relevant public events through a symmetric correlation window, and generate explanations that are factual, historical, and guardrailed. SPA relies only on daily OHLCV data and a normalized event stream, making the pipeline straight-forward to audit and easy to reproduce. To illustrate SPA's behavior in practice, we evaluate it across four equities-AAPL, NVDA, SCHW, and PGR-chosen to span a range of volatility regimes and sector characteristics. Although the evaluation period is modest, the results demonstrate how SPA consistently produces stable structural decompositions and contextual narratives. Ablation experiments further show how deterministic segmentation, event alignment, and constrained explanation each contribute to interpretability. SPA is not a forecasting system, nor is it intended to produce trading signals. Its value lies in offering a transparent, reproducible view of historical price structure that can complement analyst workflows, risk reviews, and broader explainable-AI pipelines.

</details>


### [76] [The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems](https://arxiv.org/abs/2512.15068)
*Debu Sinha*

Main category: cs.LG

TL;DR: 本文应用保形预测方法检测RAG系统中的幻觉，发现基于嵌入的方法在真实基准测试中假阳性率过高，而GPT-4作为LLM法官表现更好，揭示了"语义幻觉"问题。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成(RAG)系统基于检索证据，但仍容易产生幻觉。当前基于语义相似性和自然语言推理的检测方法存在根本性局限，需要更严格的性能评估。

Method: 应用保形预测方法进行幻觉检测，提供有限样本覆盖保证。使用约600个示例的校准集，在合成和真实幻觉基准上测试多种方法，包括基于嵌入的方法和GPT-4作为LLM法官。

Result: 在合成幻觉上达到94%覆盖率和0%假阳性率，但在三个真实基准测试中，基于嵌入的方法假阳性率过高：HaluEval 100%、RAGTruth 88%、WikiBio 50%。GPT-4作为LLM法官仅7%假阳性率，证明任务可通过推理解决。

Conclusion: 揭示了"语义幻觉"现象：语义上合理的幻觉保持了与源文档的相似性，但引入了嵌入方法无法检测的事实错误。基于嵌入的检测方法对于生产级RAG部署不足，需要更复杂的推理能力。

Abstract: Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the "semantic illusion": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.

</details>


### [77] [The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks](https://arxiv.org/abs/2512.15082)
*Wanfu Gao,Zebin He,Jun Gao*

Main category: cs.LG

TL;DR: FEAML是一种基于大语言模型的多标签学习自动化特征工程方法，通过代码生成和反馈机制优化特征质量


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的特征工程方法尚未应用于多标签学习任务，缺乏对复杂标签依赖关系的建模能力，且未针对多标签任务特性进行专门适配

Method: 利用LLM的代码生成能力，通过元数据和标签共现矩阵引导LLM理解数据特征与任务目标的关系，生成高质量特征；使用模型准确率评估特征有效性，Pearson相关系数检测冗余；将评估结果作为反馈驱动LLM在后续迭代中持续优化代码生成

Result: 在多个多标签数据集上的实证结果表明，FEAML优于其他特征工程方法

Conclusion: FEAML通过将LLM与反馈机制相结合，实现了高效、可解释且自我改进的特征工程范式

Abstract: Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

</details>


### [78] [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)
*Aaron Mueller,Andrew Lee,Shruti Joshi,Ekdeep Singh Lubana,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 该研究提出多概念评估框架，分析稀疏自编码器和稀疏探针在概念相关性增加时的解耦表示能力，发现特征与概念存在一对多关系，且概念操纵时缺乏选择性


<details>
  <summary>Details</summary>
Motivation: 当前可解释性研究通常孤立评估概念表示质量，并隐含独立性假设，但实际中概念间存在相关性。需要评估常见特征化方法（稀疏自编码器和稀疏探针）是否能真正恢复概念的解耦表示

Method: 提出多概念评估设置，控制文本概念（如情感、领域、时态）间的相关性，分析在相关性增加时的性能。首先评估特征化器在不同相关强度下学习每个概念解耦表示的能力，然后进行操纵实验，测量每个概念是否可独立操纵

Result: 观察到特征与概念存在一对多关系：特征最多对应一个概念，但概念分布在多个特征中。即使在均匀分布概念上训练，稀疏自编码器特征在操纵时通常影响多个概念，表明它们既不具有选择性也不独立；然而特征影响不相交的子空间

Conclusion: 相关性度量通常不足以在操纵时建立独立性，影响不相交子空间也不足以实现概念选择性。这些结果强调了可解释性研究中组合评估的重要性

Abstract: A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, it is unclear whether common featurization methods - including sparse autoencoders (SAEs) and sparse probes - recover disentangled representations of these concepts. This study proposes a multi-concept evaluation setting where we control the correlations between textual concepts, such as sentiment, domain, and tense, and analyze performance under increasing correlations between them. We first evaluate the extent to which featurizers can learn disentangled representations of each concept under increasing correlational strengths. We observe a one-to-many relationship from concepts to features: features correspond to no more than one concept, but concepts are distributed across many features. Then, we perform steering experiments, measuring whether each concept is independently manipulable. Even when trained on uniform distributions of concepts, SAE features generally affect many concepts when steered, indicating that they are neither selective nor independent; nonetheless, features affect disjoint subspaces. These results suggest that correlational metrics for measuring disentanglement are generally not sufficient for establishing independence when steering, and that affecting disjoint subspaces is not sufficient for concept selectivity. These results underscore the importance of compositional evaluations in interpretability research.

</details>


### [79] [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)
*Runze Li,Hanchen Wang,Wenjie Zhang,Binghao Li,Yu Zhang,Xuemin Lin,Ying Zhang*

Main category: cs.LG

TL;DR: FADTI：一种基于扩散的多元时间序列插补框架，通过可学习的傅里叶偏置投影模块注入频率感知特征调制，结合自注意力和门控卷积进行时序建模，在缺失率高的情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer和扩散的模型缺乏明确的归纳偏置和频率感知能力，限制了它们在结构化缺失模式和分布偏移下的泛化能力。多元时间序列插补在医疗、交通预测和生物建模等应用中至关重要，但传感器故障和不规则采样导致普遍缺失值。

Method: 提出FADTI框架，通过可学习的傅里叶偏置投影模块注入频率感知特征调制，支持多种谱基，能够自适应编码平稳和非平稳模式。结合自注意力和门控卷积进行时序建模，将频域归纳偏置注入生成式插补过程。

Result: 在多个基准测试（包括新引入的生物时间序列数据集）上的实验表明，FADTI始终优于最先进的方法，特别是在高缺失率情况下表现突出。

Conclusion: FADTI通过注入频率感知的归纳偏置，有效提升了多元时间序列插补的性能，特别是在处理结构化缺失模式和高缺失率场景下具有显著优势。

Abstract: Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases and frequency awareness, limiting their generalization under structured missing patterns and distribution shifts. We propose FADTI, a diffusion-based framework that injects frequency-informed feature modulation via a learnable Fourier Bias Projection (FBP) module and combines it with temporal modeling through self-attention and gated convolution. FBP supports multiple spectral bases, enabling adaptive encoding of both stationary and non-stationary patterns. This design injects frequency-domain inductive bias into the generative imputation process. Experiments on multiple benchmarks, including a newly introduced biological time series dataset, show that FADTI consistently outperforms state-of-the-art methods, particularly under high missing rates. Code is available at https://anonymous.4open.science/r/TimeSeriesImputation-52BF

</details>


### [80] [Tracking Temporal Dynamics of Vector Sets with Gaussian Process](https://arxiv.org/abs/2512.15538)
*Taichi Aida,Mamoru Komachi,Toshinobu Ogiso,Hiroya Takamura,Daichi Mochihashi*

Main category: cs.LG

TL;DR: 提出一种基于无限维高斯过程的方法，用于建模随时间变化的向量集分布，通过随机傅里叶特征获得紧凑可比的向量表示，从而在低维空间中追踪和可视化向量集的时序演变。


<details>
  <summary>Details</summary>
Motivation: 理解向量集的时序演变是生态学、犯罪分析、语言学等多个领域的基础挑战。这些向量集具有复杂的结构且随时间变化，分析难度大。需要一种能够捕捉向量集分布随时间变化的方法。

Method: 使用无限维高斯过程建模每个向量集的基础分布，通过随机傅里叶特征近似高斯过程中的潜在函数，获得紧凑且可比较的时序向量表示，实现低维空间中的追踪和可视化。

Result: 在犯罪分布数据和词嵌入数据上验证了方法的有效性，能够捕捉时序动态变化，提供可解释且稳健的表示，为分析跨领域时序索引向量集的结构变化提供了强大框架。

Conclusion: 该方法成功解决了分析时序向量集的挑战，通过高斯过程和随机傅里叶特征实现了向量集分布的建模和可视化，为跨领域时序数据分析提供了有效的工具。

Abstract: Understanding the temporal evolution of sets of vectors is a fundamental challenge across various domains, including ecology, crime analysis, and linguistics. For instance, ecosystem structures evolve due to interactions among plants, herbivores, and carnivores; the spatial distribution of crimes shifts in response to societal changes; and word embedding vectors reflect cultural and semantic trends over time. However, analyzing such time-varying sets of vectors is challenging due to their complicated structures, which also evolve over time. In this work, we propose a novel method for modeling the distribution underlying each set of vectors using infinite-dimensional Gaussian processes. By approximating the latent function in the Gaussian process with Random Fourier Features, we obtain compact and comparable vector representations over time. This enables us to track and visualize temporal transitions of vector sets in a low-dimensional space. We apply our method to both sociological data (crime distributions) and linguistic data (word embeddings), demonstrating its effectiveness in capturing temporal dynamics. Our results show that the proposed approach provides interpretable and robust representations, offering a powerful framework for analyzing structural changes in temporally indexed vector sets across diverse domains.

</details>


### [81] [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)
*Roland Baatz*

Main category: cs.LG

TL;DR: 该研究比较了机器学习模型在德国农业产量预测中的泛化性能和可解释性，发现模型在时间独立验证中表现显著下降，但SHAP特征重要性仍显示可信，揭示了可解释性方法在模型未泛化时仍可能误导用户的漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决环境数据科学中日益增长的挑战：如何足够稳健地评估机器学习模型的泛化能力，以便信任模型解释。特别是在农业和环境系统中，模型预测的可解释性对于决策制定至关重要，但当前方法存在模型可能未真正泛化时仍产生看似可信解释的漏洞。

Method: 使用德国NUTS-3地区的高质量长期数据集，系统比较了集成树模型（XGBoost、随机森林）和深度学习方法（LSTM、TCN）的评估和时间验证行为。研究采用空间分割的传统测试集和时间独立验证年份两种评估方式，并使用SHAP进行特征重要性分析。

Result: 所有模型在空间分割测试集上表现良好，但在时间独立验证年份中性能显著下降，显示出泛化能力的持续局限性。值得注意的是，测试集准确率高但时间验证性能差的模型仍能产生看似可信的SHAP特征重要性值，暴露了事后可解释性方法的严重漏洞。

Conclusion: 研究强调农业和环境系统中机器学习预测需要验证感知的解释。特征重要性不应被表面接受，除非模型明确显示能够泛化到未见的时间和空间条件。研究倡导领域感知验证、混合建模策略，以及对数据驱动农业中可解释性方法进行更严格的审查。

Abstract: This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation behavior of ensemble tree-based models (XGBoost, Random Forest) and deep learning approaches (LSTM, TCN).
  While all models perform well on spatially split, conventional test sets, their performance degrades substantially on temporally independent validation years, revealing persistent limitations in generalization. Notably, models with strong test-set accuracy, but weak temporal validation performance can still produce seemingly credible SHAP feature importance values. This exposes a critical vulnerability in post hoc explainability methods: interpretability may appear reliable even when the underlying model fails to generalize.
  These findings underscore the need for validation-aware interpretation of ML predictions in agricultural and environmental systems. Feature importance should not be accepted at face value unless models are explicitly shown to generalize to unseen temporal and spatial conditions. The study advocates for domain-aware validation, hybrid modeling strategies, and more rigorous scrutiny of explainability methods in data-driven agriculture. Ultimately, this work addresses a growing challenge in environmental data science: how can we evaluate generalization robustly enough to trust model explanations?

</details>


### [82] [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)
*Pablo Montaña-Fernández,Ines Ortega-Fernandez*

Main category: cs.LG

TL;DR: 提出一种新的联邦学习梯度成员推理攻击，利用多层梯度时间演化模式，无需访问私有数据集，适用于半诚实和恶意攻击者，并可扩展到离散属性推理。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然减少了直接数据暴露，但模型更新交换仍可能泄露敏感信息。现有攻击方法可能未充分利用多轮联邦学习中的梯度时间演化模式，需要开发更有效的隐私攻击方法。

Method: 提出基于梯度的成员推理攻击，利用影子技术学习训练记录的多轮梯度模式，无需访问私有数据集。攻击考虑半诚实和恶意攻击者（聚合器或数据所有者），并可扩展到离散属性推理，通过对比不同属性假设下的梯度响应实现。

Result: 在CIFAR-100和Purchase100数据集上评估成员推理攻击，在Breast Cancer Wisconsin数据集上评估属性推理攻击。结果显示攻击性能强劲，计算和内存开销与文献中其他攻击相当。多轮联邦学习增加推理攻击脆弱性，聚合器威胁大于数据所有者，高维数据导致更强泄露。

Conclusion: 多轮联邦学习可能增加推理攻击脆弱性，聚合器构成更大威胁，攻击性能受训练数据性质影响，高维数据导致更强泄露。提出的攻击方法模型无关，适用于任何基于梯度的模型和分类回归任务。

Abstract: Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradient-based membership inference attack for federated learning scenarios that exploits the temporal evolution of last-layer gradients across multiple federated rounds. Our method uses the shadow technique to learn round-wise gradient patterns of the training records, requiring no access to the private dataset, and is designed to consider both semi-honest and malicious adversaries (aggregators or data owners). Beyond membership inference, we also provide a natural extension of the proposed attack to discrete attribute inference by contrasting gradient responses under alternative attribute hypotheses. The proposed attacks are model-agnostic, and therefore applicable to any gradient-based model and can be applied to both classification and regression settings. We evaluate the attack on CIFAR-100 and Purchase100 datasets for membership inference and on Breast Cancer Wisconsin for attribute inference. Our findings reveal strong attack performance and comparable computational and memory overhead in membership inference when compared to another attack from the literature. The obtained results emphasize that multi-round federated learning can increase the vulnerability to inference attacks, that aggregators pose a more substantial threat than data owners, and that attack performance is strongly influenced by the nature of the training dataset, with richer, high-dimensional data leading to stronger leakage than simpler tabular data.

</details>


### [83] [Understanding NTK Variance in Implicit Neural Representations](https://arxiv.org/abs/2512.15169)
*Chengguang Ou,Yixin Zhuang*

Main category: cs.LG

TL;DR: 论文分析了隐式神经表示（INRs）中谱偏差问题的根源，通过神经正切核（NTK）理论框架解释了不同架构选择如何影响NTK条件数，并提出统一的方差分解方法。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）通常收敛缓慢且难以恢复高频细节，这归因于谱偏差问题。虽然先前工作将此行为与神经正切核（NTK）联系起来，但具体架构选择如何影响NTK条件数仍不清楚。

Method: 通过分析INR机制对少量成对相似性因子和缩放项的影响，推导出常见INR组件的闭式方差分解。研究显示：位置编码重塑输入相似性，球面归一化通过层间缩放减少方差，Hadamard调制引入严格小于1的额外相似性因子，产生乘法方差减少。

Result: 实验验证了预测的方差减少效果，证明该方法能实现更快、更稳定的收敛，并提高重建质量。统一视角解释了不同INR架构如何通过改善NTK条件数来缓解谱偏差问题。

Conclusion: 研究提供了一个统一的理论框架，解释了各种INR架构组件如何通过影响NTK特征值方差来改善谱偏差问题，为设计更高效的INR架构提供了理论基础。

Abstract: Implicit Neural Representations (INRs) often converge slowly and struggle to recover high-frequency details due to spectral bias. While prior work links this behavior to the Neural Tangent Kernel (NTK), how specific architectural choices affect NTK conditioning remains unclear. We show that many INR mechanisms can be understood through their impact on a small set of pairwise similarity factors and scaling terms that jointly determine NTK eigenvalue variance. For standard coordinate MLPs, limited input-feature interactions induce large eigenvalue dispersion and poor conditioning. We derive closed-form variance decompositions for common INR components and show that positional encoding reshapes input similarity, spherical normalization reduces variance via layerwise scaling, and Hadamard modulation introduces additional similarity factors strictly below one, yielding multiplicative variance reduction. This unified view explains how diverse INR architectures mitigate spectral bias by improving NTK conditioning. Experiments across multiple tasks confirm the predicted variance reductions and demonstrate faster, more stable convergence with improved reconstruction quality.

</details>


### [84] [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)
*Zicong Cheng,Guo-Wei Yang,Jia Li,Zhijie Deng,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.LG

TL;DR: DEER框架使用扩散大语言模型作为草稿器，通过并行解码生成长草稿段，在推理加速方面显著优于传统自回归草稿方法


<details>
  <summary>Details</summary>
Motivation: 传统推测解码使用自回归草稿模型存在两个根本问题：1) 逐步不确定性积累导致目标模型与草稿器之间的信任逐渐崩溃；2) 自回归草稿器的固有顺序解码特性。这些问题限制了推理加速效果

Method: 提出DEER框架，使用扩散大语言模型作为草稿器，采用两阶段训练流程对齐扩散草稿器与目标自回归模型，并采用单步解码策略生成长草稿段

Result: DEER达到32个token的草稿接受长度，远超EAGLE-3的10个token。在HumanEval基准测试中，使用Qwen3-30B-A3B模型时，DEER获得5.54倍加速，而EAGLE-3仅获得2.41倍加速

Conclusion: 扩散大语言模型草稿器通过其根本不同的概率建模和高效并行解码策略，能够克服传统自回归草稿器的局限性，在推测解码中实现显著的推理加速

Abstract: Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/

</details>


### [85] [Chorus: Harmonizing Context and Sensing Signals for Data-Free Model Customization in IoT](https://arxiv.org/abs/2512.15206)
*Liyu Zhang,Yejia Liu,Kwun Ho Liu,Runxi Huang,Xiaomin Ouyang*

Main category: cs.LG

TL;DR: Chorus：一种面向物联网的无数据上下文感知模型定制方法，能够在无需目标域数据的情况下适应未见过的部署条件，通过跨模态重建学习上下文表示，并使用门控头动态平衡传感器与上下文贡献。


<details>
  <summary>Details</summary>
Motivation: 现实物联网应用中，传感器数据通常在多样化和动态的上下文条件下收集，传感器放置或环境因素会显著影响数据模式和下游性能。传统域适应或泛化方法常忽略上下文信息或使用简单集成策略，导致在部署后处理未见上下文偏移时效果不佳。

Method: 1. 通过无监督跨模态重建学习有效的上下文表示，在未标记传感器数据和基于语言的上下文嵌入之间进行重建，同时正则化上下文嵌入空间以学习鲁棒、可泛化的上下文表示；2. 在有限标记样本上训练轻量级门控头，动态平衡传感器和上下文贡献——当传感器证据模糊时偏向上下文，反之亦然；3. 采用上下文缓存机制，重用缓存的上下文表示，仅在检测到上下文偏移时更新，以减少推理延迟。

Result: 在IMU、语音和WiFi感知任务中，面对多样上下文偏移，Chorus在未见上下文中的性能比最先进的基线方法高出11.3%，同时在智能手机和边缘设备上保持相当的延迟。

Conclusion: Chorus提出了一种有效的上下文感知、无数据模型定制方法，能够适应未见部署条件，通过动态平衡传感器和上下文贡献以及上下文缓存机制，在保持低延迟的同时显著提升性能。

Abstract: In real-world IoT applications, sensor data is usually collected under diverse and dynamic contextual conditions where factors such as sensor placements or ambient environments can significantly affect data patterns and downstream performance. Traditional domain adaptation or generalization methods often ignore such context information or use simplistic integration strategies, making them ineffective in handling unseen context shifts after deployment. In this paper, we propose Chorus, a context-aware, data-free model customization approach that adapts models to unseen deployment conditions without requiring target-domain data. The key idea is to learn effective context representations that capture their influence on sensor data patterns and to adaptively integrate them based on the degree of context shift. Specifically, Chorus first performs unsupervised cross-modal reconstruction between unlabeled sensor data and language-based context embeddings, while regularizing the context embedding space to learn robust, generalizable context representations. Then, it trains a lightweight gated head on limited labeled samples to dynamically balance sensor and context contributions-favoring context when sensor evidence is ambiguous and vice versa. To further reduce inference latency, Chorus employs a context-caching mechanism that reuses cached context representations and updates only upon detected context shifts. Experiments on IMU, speech, and WiFi sensing tasks under diverse context shifts show that Chorus outperforms state-of-the-art baselines by up to 11.3% in unseen contexts, while maintaining comparable latency on smartphone and edge devices.

</details>


### [86] [O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization](https://arxiv.org/abs/2512.15229)
*Elio Gruttadauria,Mathieu Fontaine,Jonathan Le Roux,Slim Essid*

Main category: cs.LG

TL;DR: O-EENC-SD是一种基于EEND-EDA的端到端在线说话人日志系统，采用RNN拼接机制和质心细化解码器，在双人电话对话场景中达到SOTA水平，在复杂度和性能间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有说话人日志方法存在局限性：无监督聚类方法需要调参，当前在线端到端方法计算成本高。需要开发一个超参数少、计算效率高的在线说话人日志系统。

Method: 基于EEND-EDA框架，引入RNN拼接机制处理在线预测，开发质心细化解码器，通过消融研究验证其有效性。系统处理独立块且无重叠，实现极高效率。

Result: 在CallHome数据集的双人电话对话测试中，O-EENC-SD与最先进方法竞争，在DER和复杂度之间提供良好权衡，即使处理无重叠的独立块也能保持高效。

Conclusion: O-EENC-SD是一个超参数少、计算高效的在线说话人日志系统，在双人电话对话领域具有竞争力，为实际应用提供了性能与效率的平衡解决方案。

Abstract: We introduce O-EENC-SD: an end-to-end online speaker diarization system based on EEND-EDA, featuring a novel RNN-based stitching mechanism for online prediction. In particular, we develop a novel centroid refinement decoder whose usefulness is assessed through a rigorous ablation study. Our system provides key advantages over existing methods: a hyperparameter-free solution compared to unsupervised clustering approaches, and a more efficient alternative to current online end-to-end methods, which are computationally costly. We demonstrate that O-EENC-SD is competitive with the state of the art in the two-speaker conversational telephone speech domain, as tested on the CallHome dataset. Our results show that O-EENC-SD provides a great trade-off between DER and complexity, even when working on independent chunks with no overlap, making the system extremely efficient.

</details>


### [87] [Leveraging Foundational Models and Simple Fusion for Multi-modal Physiological Signal Analysis](https://arxiv.org/abs/2512.15250)
*Youssef Ghallab,Omar Iraqy,Mohamed Kandil,Mohamed Ashraf,Saadeldine Eletter,Morougue Ghazal,Ayman Khalafallah,Nagwa El-Makky*

Main category: cs.LG

TL;DR: 该研究提出了一种多模态生理信号整合方法，通过自监督预训练ECG编码器并与预训练的EEG编码器结合，使用简单的嵌入拼接实现跨模态融合，在情感识别任务上取得了接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）和脑电图（EEG）等生理信号为人类健康和认知提供了互补的洞察，但由于多模态标记数据有限以及模态特异性差异，多模态整合具有挑战性。需要开发能够有效整合这些互补信号的方法。

Method: 1. 采用CBraMod编码器进行大规模自监督ECG预训练，引入双掩码策略捕捉导联内和导联间依赖关系；2. 使用预训练的CBraMod编码器处理EEG信号；3. 预训练对称的ECG编码器，为每种模态提供丰富的基础表示；4. 通过简单的嵌入拼接融合这些表示，让分类头学习跨模态交互。

Result: 在情感识别任务上，该方法实现了接近最先进的性能，表明精心设计的生理编码器即使采用简单的融合方式也能显著提升下游任务性能。

Conclusion: 基础模型方法能够利用生理信号的整体特性，为医疗保健和情感计算提供可扩展、标签高效且可泛化的解决方案。精心设计的生理编码器与简单融合策略相结合，可以有效克服多模态数据有限的挑战。

Abstract: Physiological signals such as electrocardiograms (ECG) and electroencephalograms (EEG) provide complementary insights into human health and cognition, yet multi-modal integration is challenging due to limited multi-modal labeled data, and modality-specific differences . In this work, we adapt the CBraMod encoder for large-scale self-supervised ECG pretraining, introducing a dual-masking strategy to capture intra- and inter-lead dependencies. To overcome the above challenges, we utilize a pre-trained CBraMod encoder for EEG and pre-train a symmetric ECG encoder, equipping each modality with a rich foundational representation. These representations are then fused via simple embedding concatenation, allowing the classification head to learn cross-modal interactions, together enabling effective downstream learning despite limited multi-modal supervision. Evaluated on emotion recognition, our approach achieves near state-of-the-art performance, demonstrating that carefully designed physiological encoders, even with straightforward fusion, substantially improve downstream performance. These results highlight the potential of foundation-model approaches to harness the holistic nature of physiological signals, enabling scalable, label-efficient, and generalizable solutions for healthcare and affective computing.

</details>


### [88] [Topological Metric for Unsupervised Embedding Quality Evaluation](https://arxiv.org/abs/2512.15285)
*Aleksei Shestov,Anton Klenitskiy,Daria Denisova,Amurkhan Dzagkoev,Daniil Petrovich,Andrey Savchenko,Maksim Makarenko*

Main category: cs.LG

TL;DR: 提出了一种基于持续同调的拓扑感知度量方法Persistence，用于无监督评估嵌入空间的质量，无需标签即可量化几何结构和拓扑丰富性。


<details>
  <summary>Details</summary>
Motivation: 随着无监督和自监督方法在大规模无标签数据上的广泛应用，如何在没有标签的情况下评估嵌入质量成为一个开放挑战。现有方法通常假设线性可分性或依赖协方差结构，无法捕捉嵌入空间的全局和多尺度组织特征。

Method: 提出了Persistence度量方法，基于持续同调（persistent homology）这一拓扑学工具，能够量化嵌入空间的几何结构和拓扑丰富性。该方法完全无监督，不依赖标签信息，能够捕捉全局和多尺度的空间组织特征。

Result: 在多个领域的实证结果表明，Persistence在下游任务性能相关性方面始终达到顶级水平，优于现有的无监督度量方法，能够可靠地用于模型选择和超参数调优。

Conclusion: Persistence作为一种拓扑感知的无监督度量方法，能够有效评估嵌入空间的质量，解决了无监督表示学习中评估嵌入质量的挑战，为模型开发和优化提供了可靠的工具。

Abstract: Modern representation learning increasingly relies on unsupervised and self-supervised methods trained on large-scale unlabeled data. While these approaches achieve impressive generalization across tasks and domains, evaluating embedding quality without labels remains an open challenge. In this work, we propose Persistence, a topology-aware metric based on persistent homology that quantifies the geometric structure and topological richness of embedding spaces in a fully unsupervised manner. Unlike metrics that assume linear separability or rely on covariance structure, Persistence captures global and multi-scale organization. Empirical results across diverse domains show that Persistence consistently achieves top-tier correlations with downstream performance, outperforming existing unsupervised metrics and enabling reliable model and hyperparameter selection.

</details>


### [89] [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)
*Hiroyoshi Nagahama,Katsufumi Inoue,Masayoshi Todorokihara,Michifumi Yoshioka*

Main category: cs.LG

TL;DR: 该论文提出两种相位感知预处理策略来处理多轴振动数据中的随机相位变化，通过相位对齐方法显著提升了旋转机械预测性维护的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的旋转机械预测性维护方法要么在频谱特征提取时丢弃相位信息，要么使用原始时间波形而不显式利用相位信息。多轴振动数据中的随机相位变化限制了现有方法的性能。

Method: 提出两种相位感知预处理策略：1）三轴独立相位调整，将每个轴单独对齐到零相位；2）单轴参考相位调整，通过统一的时间偏移保持轴间关系。使用新构建的同步三轴传感器转子数据集，在两级学习框架下评估六种深度学习架构。

Result: 两种方法均带来架构无关的性能提升：三轴独立方法实现一致增益（Transformer提升2.7%），单轴参考方法通过保持空间相位关系实现高达96.2%的准确率（提升5.4%）。

Conclusion: 两种相位对齐策略被确立为预测性维护系统实用且可扩展的增强方法，相位信息对旋转机械故障诊断具有重要价值。

Abstract: Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preprocessing strategies to address random phase variations in multi-axis vibration data: (1) three-axis independent phase adjustment that aligns each axis individually to zero phase (2) single-axis reference phase adjustment that preserves inter-axis relationships by applying uniform time shifts. Using a newly constructed rotor dataset acquired with a synchronized three-axis sensor, we evaluate six deep learning architectures under a two-stage learning framework. Results demonstrate architecture-independent improvements: the three-axis independent method achieves consistent gains (+2.7\% for Transformer), while the single-axis reference approach delivers superior performance with up to 96.2\% accuracy (+5.4\%) by preserving spatial phase relationships. These findings establish both phase alignment strategies as practical and scalable enhancements for predictive maintenance systems.

</details>


### [90] [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)
*Honey Singh Chauhan,Zahraa S. Abdallah*

Main category: cs.LG

TL;DR: F3是一个轻量级框架，通过自适应融合Rocket、Sax和Sfa三种表示方法，在特定类型的时间序列数据集上能稳定提升分类性能，特别是在具有结构化变异性或丰富频率内容的数据集上。


<details>
  <summary>Details</summary>
Motivation: 虽然基于核的方法如Rocket在单变量时间序列分类中非常有效，但它们在不同数据集上的表现并不均衡。研究者重新审视了不同表示方法能捕捉互补结构的长期直觉，希望通过选择性融合这些表示来获得比Rocket更一致的改进。

Method: 提出了Fusion-3(F3)框架，自适应融合Rocket、Sax和Sfa三种表示。通过元特征将UCR数据集聚类为六个可解释的数据结构类别，使用三种互补分析：跨数据集的非参数配对统计、消融研究以及SHAP归因分析，还进行了样本级案例研究。

Result: 在113个UCR数据集上的5折交叉验证显示，F3相比Rocket获得了小而一致的平均改进，特别是在具有结构化变异性或丰富频率内容的数据集上表现更好。融合主要通过纠正特定错误来提升性能，在高度不规则或异常值较多的设置中收益递减。

Conclusion: 选择性应用的融合为强大的基于核的方法提供了可靠且可解释的扩展，能够在数据支持的情况下精确纠正其弱点。该方法在特定可系统识别的数据集类型上能提供一致改进。

Abstract: Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and show that selectively fusing them can yield consistent improvements over Rocket on specific, systematically identifiable kinds of datasets. We introduce Fusion-3 (F3), a lightweight framework that adaptively fuses Rocket, Sax, and Sfa representations. To understand when fusion helps, we cluster UCR datasets into six groups using meta-features capturing series length, spectral structure, roughness, and class imbalance, and treat these clusters as interpretable data-structure regimes. Our analysis shows that fusion typically outperforms strong baselines in regimes with structured variability or rich frequency content, while offering diminishing returns in highly irregular or outlier-heavy settings. To support these findings, we combine three complementary analyses: non-parametric paired statistics across datasets, ablation studies isolating the roles of individual representations, and attribution via SHAP to identify which dataset properties predict fusion gains. Sample-level case studies further reveal the underlying mechanism: fusion primarily improves performance by rescuing specific errors, with adaptive increases in frequency-domain weighting precisely where corrections occur. Using 5-fold cross-validation on the 113 UCR datasets, F3 yields small but consistent average improvements over Rocket, supported by frequentist and Bayesian evidence and accompanied by clearly identifiable failure cases. Our results show that selectively applied fusion provides dependable and interpretable extension to strong kernel-based methods, correcting their weaknesses precisely where the data support it.

</details>


### [91] [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)
*Julian Oelhaf,Mehran Pashaei,Georg Kordowich,Christian Bergler,Andreas Maier,Johann Jäger,Siming Bayer*

Main category: cs.LG

TL;DR: 该研究提出了一个系统性评估电力系统保护中机器学习模型鲁棒性的统一框架，通过高保真电磁暂态仿真模拟传感器故障、采样率降低等实际退化场景，发现故障分类在多数退化情况下保持稳定，而故障定位对电压数据丢失更为敏感。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源和分布式发电的渗透率不断提高，传统依赖固定设置和本地测量的保护方案面临挑战。机器学习为集中式故障分类和定位提供了数据驱动的替代方案，但实际部署的关键在于鲁棒性——保护算法必须在面对缺失、噪声或退化的传感器数据时仍保持可靠。

Method: 研究引入了一个统一的框架，使用高保真电磁暂态仿真来模拟现实的退化场景，包括传感器故障、采样率降低和瞬态通信丢失。该框架提供了一致的基准测试方法，用于量化有限可观测性的影响，并识别弹性运行所需的关键测量通道。

Result: 结果显示：故障分类在大多数退化类型下保持高度稳定，但在单相数据丢失情况下性能下降约13%；故障定位总体上更为敏感，电压数据丢失会使定位误差增加超过150%。

Conclusion: 这些发现为未来机器学习辅助保护系统的鲁棒性设计提供了可操作的指导，强调了在保护算法设计中考虑数据退化场景的重要性，特别是对于故障定位任务需要特别关注电压测量的可靠性。

Abstract: The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault localization (FL), enabling faster and more adaptive decision-making. However, practical deployment critically depends on robustness. Protection algorithms must remain reliable even when confronted with missing, noisy, or degraded sensor data. This work introduces a unified framework for systematically evaluating the robustness of ML models in power system protection.
  High-fidelity EMT simulations are used to model realistic degradation scenarios, including sensor outages, reduced sampling rates, and transient communication losses. The framework provides a consistent methodology for benchmarking models, quantifying the impact of limited observability, and identifying critical measurement channels required for resilient operation. Results show that FC remains highly stable under most degradation types but drops by about 13% under single-phase loss, while FL is more sensitive overall, with voltage loss increasing localization error by over 150%. These findings offer actionable guidance for robustness-aware design of future ML-assisted protection systems.

</details>


### [92] [EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning](https://arxiv.org/abs/2512.15405)
*Jianfei Ma,Wee Sun Lee*

Main category: cs.LG

TL;DR: 提出EUBRL算法，利用认知不确定性指导探索，在无限时域折扣MDP中实现近乎极小极大最优的遗憾和样本复杂度


<details>
  <summary>Details</summary>
Motivation: 智能体在已知与未知边界面临探索与利用的困境，认知不确定性反映了知识有限导致的系统性不确定性，需要一种能利用认知指导进行原则性探索的强化学习算法

Method: 提出贝叶斯强化学习算法EUBRL，利用认知不确定性指导探索，自适应减少由估计误差引起的每步遗憾，适用于具有充分表达能力先验的无限时域折扣MDP

Result: 理论证明EUBRL在无限时域折扣MDP中具有近乎极小极大最优的遗憾和样本复杂度保证；实证评估显示在稀疏奖励、长时域和随机性任务中，EUBRL具有优越的样本效率、可扩展性和一致性

Conclusion: EUBRL通过认知不确定性指导实现了原则性探索，在理论和实证上都表现出色，为解决探索-利用困境提供了有效方法

Abstract: At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.

</details>


### [93] [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)
*Yeonwoo Cha,Semin Kim,Jinhyeon Kwon,Seunghoon Hong*

Main category: cs.LG

TL;DR: FlowBind是一个高效的任意到任意生成框架，通过共享潜在空间和模态特定可逆流实现跨模态转换，相比现有方法参数减少6倍、训练速度提升10倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于流的方法存在效率低下问题：需要大规模数据集且配对约束严格，建模联合分布计算成本高，依赖复杂的多阶段训练。需要一种更简单高效的任意到任意生成框架。

Method: FlowBind学习一个捕获跨模态信息的共享潜在空间，通过模态特定的可逆流将每个模态桥接到这个潜在空间。两个组件在单一流匹配目标下联合优化，推理时这些可逆流作为编码器和解码器实现跨模态直接转换。

Result: 在文本、图像和音频上的实验表明，FlowBind在保持可比生成质量的同时，参数减少高达6倍，训练速度提升10倍，显著降低了数据需求和计算成本。

Conclusion: FlowBind通过因子化交互到共享潜在空间，实现了高效的任意到任意生成，能够自然地利用任意模态子集进行训练，在减少参数和加速训练的同时保持竞争性生成质量。

Abstract: Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, incur high computational cost from modeling joint distribution, and rely on complex multi-stage training. We propose FlowBind, an efficient framework for any-to-any generation. Our approach is distinguished by its simplicity: it learns a shared latent space capturing cross-modal information, with modality-specific invertible flows bridging this latent to each modality. Both components are optimized jointly under a single flow-matching objective, and at inference the invertible flows act as encoders and decoders for direct translation across modalities. By factorizing interactions through the shared latent, FlowBind naturally leverages arbitrary subsets of modalities for training, and achieves competitive generation quality while substantially reducing data requirements and computational cost. Experiments on text, image, and audio demonstrate that FlowBind attains comparable quality while requiring up to 6x fewer parameters and training 10x faster than prior methods. The project page with code is available at https://yeonwoo378.github.io/official_flowbind.

</details>


### [94] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada,Shu Tanaka*

Main category: cs.LG

TL;DR: 该研究探讨了随机矩阵中最小-最大归一化特征值的统计特性，包括累积分布的标度律和矩阵分解中的残差误差，并通过数值实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 在数据科学实践中，输入数据通常需要先进行归一化处理。随机矩阵理论在纯数学、数学物理和机器学习等多个领域都发挥着重要作用，因此研究归一化特征值的统计特性具有实际意义。

Method: 应用先前提出的归一化特征值有效分布来评估累积分布的标度律，推导随机矩阵矩阵分解过程中产生的残差误差，并通过数值实验验证理论预测。

Result: 获得了归一化特征值累积分布的标度律，推导出了矩阵分解的残差误差表达式，数值实验结果与理论预测一致。

Conclusion: 该研究为随机矩阵中归一化特征值的统计特性提供了理论分析和实验验证，对数据科学中的归一化处理具有指导意义。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [95] [Double Horizon Model-Based Policy Optimization](https://arxiv.org/abs/2512.15439)
*Akihiro Kubo,Paavo Parmas,Shin Ishii*

Main category: cs.LG

TL;DR: DHMBPO提出双视野模型强化学习方法，通过长分布视野和短训练视野分离，解决模型偏差、分布偏移和梯度不稳定之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 基于模型的强化学习中，选择视野长度面临两个困境：长视野能更好保持同策略训练但会放大模型偏差，需要中间视野缓解分布偏移；同时长视野可能减少价值估计偏差但会增加策略梯度方差。这两个最优视野可能不同，需要解决这一冲突。

Method: 提出双视野模型策略优化（DHMBPO），将视野过程分为长"分布视野"（DR）和短"训练视野"（TR）。DR生成同策略状态样本以缓解分布偏移，而短TR利用可微分转移提供准确的价值梯度估计，实现稳定梯度更新，减少更新次数和总运行时间。

Result: 双视野方法有效平衡了分布偏移、模型偏差和梯度不稳定性，在连续控制基准测试中，在样本效率和运行时间方面都超越了现有的基于模型的强化学习方法。

Conclusion: DHMBPO通过分离分布视野和训练视野，解决了模型强化学习中视野长度选择的根本冲突，实现了更好的性能平衡，为基于模型的强化学习提供了有效的解决方案。

Abstract: Model-based reinforcement learning (MBRL) reduces the cost of real-environment sampling by generating synthetic trajectories (called rollouts) from a learned dynamics model. However, choosing the length of the rollouts poses two dilemmas: (1) Longer rollouts better preserve on-policy training but amplify model bias, indicating the need for an intermediate horizon to mitigate distribution shift (i.e., the gap between on-policy and past off-policy samples). (2) Moreover, a longer model rollout may reduce value estimation bias but raise the variance of policy gradients due to backpropagation through multiple steps, implying another intermediate horizon for stable gradient estimates. However, these two optimal horizons may differ. To resolve this conflict, we propose Double Horizon Model-Based Policy Optimization (DHMBPO), which divides the rollout procedure into a long "distribution rollout" (DR) and a short "training rollout" (TR). The DR generates on-policy state samples for mitigating distribution shift. In contrast, the short TR leverages differentiable transitions to offer accurate value gradient estimation with stable gradient updates, thereby requiring fewer updates and reducing overall runtime. We demonstrate that the double-horizon approach effectively balances distribution shift, model bias, and gradient instability, and surpasses existing MBRL methods on continuous-control benchmarks in terms of both sample efficiency and runtime.

</details>


### [96] [Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting](https://arxiv.org/abs/2512.15442)
*Neeraj Sarna,Yuanyuan Li,Michael von Gablenz*

Main category: cs.LG

TL;DR: 本文研究如何通过思维链和任务指令提示等技术减少文本到图像生成模型中的版权内容生成，降低侵权风险。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像生成模型可能会记忆并重现其训练数据中的受版权保护内容，这给AI用户和开发者带来法律风险和财务损失，因此需要探索减少版权内容生成的方法。

Method: 提出了一种结合思维链和任务指令提示的框架，并与两种版权缓解策略结合：a)负面提示，b)提示重写。通过评估生成图像与版权图像的相似度以及与用户输入的相关性来研究这些技术。

Result: 在不同复杂度的模型上进行了数值实验，提供了关于这些技术在减少版权内容生成方面有效性的见解。

Conclusion: 思维链和任务指令提示结合负面提示和提示重写等技术可以有效减少文本到图像生成模型中的版权内容生成，为降低侵权风险提供了可行方案。

Abstract: Large scale text-to-image generation models can memorize and reproduce their training dataset. Since the training dataset often contains copyrighted material, reproduction of training dataset poses a copyright infringement risk, which could result in legal liabilities and financial losses for both the AI user and the developer. The current works explores the potential of chain-of-thought and task instruction prompting in reducing copyrighted content generation. To this end, we present a formulation that combines these two techniques with two other copyright mitigation strategies: a) negative prompting, and b) prompt re-writing. We study the generated images in terms their similarity to a copyrighted image and their relevance of the user input. We present numerical experiments on a variety of models and provide insights on the effectiveness of the aforementioned techniques for varying model complexity.

</details>


### [97] [From Risk to Resilience: Towards Assessing and Mitigating the Risk of Data Reconstruction Attacks in Federated Learning](https://arxiv.org/abs/2512.15460)
*Xiangrui Xu,Zhize Li,Yufei Han,Bin Wang,Jiqiang Liu,Wei Wang*

Main category: cs.LG

TL;DR: 提出Invertibility Loss (InvLoss)量化联邦学习中数据重建攻击的最大风险，推导其可计算上界，并开发InvRE风险估计器和自适应噪声防御方法


<details>
  <summary>Details</summary>
Motivation: 联邦学习系统中的数据重建攻击威胁严重，但缺乏理论基础的量化框架来评估风险，需要系统性的风险评估和缓解方法

Method: 引入Invertibility Loss量化数据重建攻击的最大有效性，推导其紧致可计算上界，基于此开发InvRE风险估计器，并提出两种自适应噪声扰动防御方法

Result: 实验验证框架有效性，显示DRA风险由Jacobian矩阵谱特性决定，InvRE提供攻击方法无关的全面风险评估，自适应防御增强隐私而不损害分类精度

Conclusion: 提出的InvLoss框架为联邦学习系统提供了系统性的数据重建攻击风险评估和缓解方法，填补了理论空白并具有实际应用价值

Abstract: Data Reconstruction Attacks (DRA) pose a significant threat to Federated Learning (FL) systems by enabling adversaries to infer sensitive training data from local clients. Despite extensive research, the question of how to characterize and assess the risk of DRAs in FL systems remains unresolved due to the lack of a theoretically-grounded risk quantification framework. In this work, we address this gap by introducing Invertibility Loss (InvLoss) to quantify the maximum achievable effectiveness of DRAs for a given data instance and FL model. We derive a tight and computable upper bound for InvLoss and explore its implications from three perspectives. First, we show that DRA risk is governed by the spectral properties of the Jacobian matrix of exchanged model updates or feature embeddings, providing a unified explanation for the effectiveness of defense methods. Second, we develop InvRE, an InvLoss-based DRA risk estimator that offers attack method-agnostic, comprehensive risk evaluation across data instances and model architectures. Third, we propose two adaptive noise perturbation defenses that enhance FL privacy without harming classification accuracy. Extensive experiments on real-world datasets validate our framework, demonstrating its potential for systematic DRA risk evaluation and mitigation in FL systems.

</details>


### [98] [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)
*Alexandre Dussolle,Pietro Liò*

Main category: cs.LG

TL;DR: 提出N-单纯形注意力机制，从成对token相似性扩展到高阶交互，适配RoPE位置编码，通过成本有效的单纯形选择管理复杂度，并分析其平滑性特征


<details>
  <summary>Details</summary>
Motivation: 从纯MLP到可学习的图消息传递机制（如GAT或Transformer）已取得最先进结果，但存在计算权衡。为进一步提升，需要从成对token相似性扩展到更高阶的交互

Method: 1. 引入N-单纯形注意力机制，将注意力从成对token相似性扩展到高阶交互；2. 适配Rotary Position Embeddings (RoPE)；3. 提出成本有效的单纯形选择机制，使模型能将计算集中在任务敏感度更高的交互上

Result: 1. 推导了N-单纯形注意力的Lipschitz上界，分析了其平滑性；2. 证明了尽管开启了高阶交互的消息传递，但该机制本身也会遭受过平滑问题

Conclusion: N-单纯形注意力机制为从成对交互扩展到高阶交互提供了新途径，通过单纯形选择管理复杂度，但需要注意其固有的过平滑问题

Abstract: Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going from pairwise token similarity to higher-order interactions, and adapt it for Rotary Position Embeddings (RoPE). To help manage the increased complexity, we propose a cost-effective simplex selection enabling the model to focus its computation load onto the more task-sensitive interactions. Beyond these core mechanisms, we study how smoothing N-simplicial attention is by deriving a Lipschitz upper-bound and by demonstrating that by itself it also suffers from over-smoothing, despite opening the attention message-passing to higher-order interactions.

</details>


### [99] [Robustness and uncertainty: two complementary aspects of the reliability of the predictions of a classifier](https://arxiv.org/abs/2512.15492)
*Adrián Detavernier,Jasper De Bock*

Main category: cs.LG

TL;DR: 本文比较了评估分类器个体预测可靠性的两种方法：鲁棒性量化(RQ)和不确定性量化(UQ)，发现两者互补，结合后的混合方法优于单独使用任一种方法。


<details>
  <summary>Details</summary>
Motivation: 评估分类器个体预测的可靠性对于实际应用至关重要，但目前存在两种概念不同的方法：鲁棒性量化(RQ)和不确定性量化(UQ)。需要研究这两种方法的相对优势和互补性，以提供更好的可靠性评估方案。

Method: 在多个基准数据集上系统比较RQ和UQ两种方法，分析它们的性能差异和互补性。基于比较结果，开发一种结合两者优势的混合方法，并评估每种方法对预测不可靠性的相对贡献。

Result: 实验表明RQ和UQ没有明显的优劣之分，但具有互补性。结合两者的混合方法在可靠性评估方面优于单独使用任一种方法。此外，研究还量化了不确定性和鲁棒性作为不可靠性来源的相对重要性。

Conclusion: RQ和UQ是评估分类器预测可靠性的两种互补方法，结合使用可以获得更好的性能。研究还提供了评估不确定性和鲁棒性相对重要性的框架，有助于更全面地理解预测不可靠性的来源。

Abstract: We consider two conceptually different approaches for assessing the reliability of the individual predictions of a classifier: Robustness Quantification (RQ) and Uncertainty Quantification (UQ). We compare both approaches on a number of benchmark datasets and show that there is no clear winner between the two, but that they are complementary and can be combined to obtain a hybrid approach that outperforms both RQ and UQ. As a byproduct of our approach, for each dataset, we also obtain an assessment of the relative importance of uncertainty and robustness as sources of unreliability.

</details>


### [100] [Joint Learning of Unsupervised Multi-view Feature and Instance Co-selection with Cross-view Imputation](https://arxiv.org/abs/2512.15574)
*Yuxin Cai,Yanyong Huang,Jinyuan Chang,Dongjie Wang,Tianrui Li,Xiaoyi Jiang*

Main category: cs.LG

TL;DR: JUICE是一个联合学习框架，用于无监督多视图特征和实例协同选择，同时进行跨视图缺失数据填补，通过统一框架提升选择效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理无标签不完整多视图数据时，通常先填补缺失数据再拼接视图进行协同选择，将这两个过程视为独立，忽略了它们之间的潜在交互。同时，简单合并多视图数据无法捕捉视图间的互补信息，限制了协同选择效果。

Method: JUICE首先利用可用观测重建不完整多视图数据，将缺失数据恢复与特征和实例协同选择统一在一个框架中。然后利用跨视图邻域信息学习样本间关系，在重建过程中进一步优化缺失值填补，从而选择更具代表性的特征和实例。

Result: 大量实验表明，JUICE在性能上优于现有的最先进方法。

Conclusion: JUICE通过将缺失数据填补与特征实例协同选择统一在联合学习框架中，并利用跨视图信息增强样本关系学习，显著提升了无监督多视图数据协同选择的效果。

Abstract: Feature and instance co-selection, which aims to reduce both feature dimensionality and sample size by identifying the most informative features and instances, has attracted considerable attention in recent years. However, when dealing with unlabeled incomplete multi-view data, where some samples are missing in certain views, existing methods typically first impute the missing data and then concatenate all views into a single dataset for subsequent co-selection. Such a strategy treats co-selection and missing data imputation as two independent processes, overlooking potential interactions between them. The inter-sample relationships gleaned from co-selection can aid imputation, which in turn enhances co-selection performance. Additionally, simply merging multi-view data fails to capture the complementary information among views, ultimately limiting co-selection effectiveness. To address these issues, we propose a novel co-selection method, termed Joint learning of Unsupervised multI-view feature and instance Co-selection with cross-viEw imputation (JUICE). JUICE first reconstructs incomplete multi-view data using available observations, bringing missing data recovery and feature and instance co-selection together in a unified framework. Then, JUICE leverages cross-view neighborhood information to learn inter-sample relationships and further refine the imputation of missing values during reconstruction. This enables the selection of more representative features and instances. Extensive experiments demonstrate that JUICE outperforms state-of-the-art methods.

</details>


### [101] [Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2512.15687)
*Zhenwen Liang,Sidi Lu,Wenhao Yu,Kishan Panaganti,Yujun Zhou,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: G2RL提出了一种基于梯度引导的强化学习框架，用模型自身的一阶更新几何来指导探索，而不是依赖外部启发式方法，在数学和通用推理基准上显著优于传统的熵奖励方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习中的探索机制（如熵奖励和外部语义比较器）与大型语言模型的实际学习方式存在根本性不匹配。这些方法鼓励表面层面的变化，但不能保证采样轨迹在影响优化的更新方向上存在差异。

Method: G2RL框架利用模型自身的一阶更新几何来指导探索。对于每个响应，从模型最后一层的敏感度构建序列级特征（可通过标准前向传播以极低成本获得），然后通过比较采样组内的这些特征来衡量每个轨迹如何重塑策略。引入新颖梯度方向的轨迹获得有界的乘法奖励缩放，而冗余或离流形的更新则被弱化。

Result: 在Qwen3基础1.7B和4B模型上，在数学和通用推理基准（MATH500、AMC、AIME24、AIME25、GPQA、MMLUpro）上，G2RL在pass@1、maj@16和pass@k指标上持续优于基于熵的GRPO和外部嵌入方法。分析显示，G2RL将探索扩展到更多正交且常常相反的梯度方向，同时保持语义连贯性。

Conclusion: 策略自身的更新空间为大型语言模型强化学习中的探索指导提供了更忠实和有效的基础，G2RL框架通过利用模型的一阶更新几何实现了与PPO风格稳定性和KL控制自然对齐的自参照探索信号。

Abstract: Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.

</details>


### [102] [Corrective Diffusion Language Models](https://arxiv.org/abs/2512.15596)
*Shuibai Zhang,Fred Zhangzhi Peng,Yiheng Zhang,Jin Pan,Grigorios G. Chrysos*

Main category: cs.LG

TL;DR: 该论文研究了扩散语言模型的纠错能力，发现传统掩码扩散训练无法可靠地实现错误定位和修正，提出了一种纠错导向的后训练方法，显著提升了模型在代码修正任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在结构上适合迭代错误修正，但标准的掩码扩散语言模型训练无法可靠地诱导这种纠错行为，因为模型往往无法识别完整输入中的不可靠标记，导致基于置信度的修正无效。

Method: 提出了一种纠错导向的后训练原则，明确监督可见的错误标记，使模型能够进行错误感知的置信度评估和针对性修正。同时引入了代码修正基准（CRB）来评估错误定位和原位修正能力。

Result: 实验表明，采用该方法训练的模型在代码修正任务和受控设置中显著优于标准掩码扩散语言模型，同时还能提升纯补全性能。

Conclusion: 扩散语言模型的纠错能力需要专门的训练方法，提出的纠错导向后训练方法有效提升了模型的错误定位和修正能力，为扩散语言模型的实际应用提供了重要改进。

Abstract: Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.

</details>


### [103] [Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction](https://arxiv.org/abs/2512.15605)
*Mathieu Blondel,Michael E. Sander,Germain Vivier-Ardisson,Tianlin Liu,Vincent Roulet*

Main category: cs.LG

TL;DR: 该论文建立了自回归模型(ARMs)与能量模型(EBMs)在函数空间中的显式双射关系，揭示了它们在监督学习中的等价性，并分析了EBMs蒸馏到ARMs的理论误差界限。


<details>
  <summary>Details</summary>
Motivation: 自回归模型是目前大语言模型的主导范式，而能量模型在LLM发展中较少使用，但自然地表征了后训练对齐中的最优策略。作者希望为这两类模型提供统一视角，理解ARMs为何能在基于下一个token预测的范式下进行前瞻规划。

Method: 从概率链式法则出发，在函数空间中建立ARMs和EBMs之间的显式双射关系，证明这对应于最大熵强化学习中的软贝尔曼方程特例。基于此双射，推导ARMs和EBMs在监督学习中的等价性，并分析EBMs蒸馏到ARMs的理论误差界限。

Result: 建立了ARMs和EBMs之间的理论等价关系，证明了监督学习中的等价性，提供了EBMs蒸馏到ARMs的理论误差界限，为理解ARMs的前瞻规划能力提供了理论依据。

Conclusion: 该研究为自回归模型和能量模型提供了统一的理论框架，揭示了它们之间的深刻联系，解释了ARMs为何能在基于下一个token预测的范式下展现出前瞻规划能力，为LLM的理论理解和实际应用提供了新视角。

Abstract: Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.

</details>


### [104] [Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary](https://arxiv.org/abs/2512.15614)
*Xinshun Feng,Mingzhe Liu,Yi Qiao,Tongyu Zhu,Leilei Sun,Shuai Wang*

Main category: cs.LG

TL;DR: BEAT是一个统一可迁移的推荐框架，将用户和物品行为转化为离散可解释的序列，通过向量量化自编码构建行为词汇表，解耦宏观兴趣和微观意图，并嵌入冻结语言模型实现零样本推荐和解释生成。


<details>
  <summary>Details</summary>
Motivation: 现有可解释推荐方法依赖ID表示，掩盖了语义含义并对语言模型施加结构约束，限制了在开放场景中的应用。真实世界交互复杂，用户意图多样且协作信号与语言语义不对齐。

Method: 提出BEAT框架：1) 通过向量量化自编码构建行为词汇表，从图表示中解耦宏观兴趣和微观意图；2) 引入多级语义监督桥接行为信号和语言空间；3) 设计语义对齐正则化机制，将行为标记直接嵌入冻结语言模型的输入空间。

Result: 在三个公共数据集上的实验表明，BEAT提高了零样本推荐性能，同时生成连贯且信息丰富的解释。进一步分析显示行为标记捕获了细粒度语义，并为将复杂行为模式集成到大型语言模型中提供了即插即用接口。

Conclusion: BEAT通过将行为转化为离散可解释序列，有效解决了现有可解释推荐方法的局限性，实现了语义对齐和零样本推荐能力，为行为模式与语言模型的集成提供了新途径。

Abstract: Recent advances in explainable recommendations have explored the integration of language models to analyze natural language rationales for user-item interactions. Despite their potential, existing methods often rely on ID-based representations that obscure semantic meaning and impose structural constraints on language models, thereby limiting their applicability in open-ended scenarios. These challenges are intensified by the complex nature of real-world interactions, where diverse user intents are entangled and collaborative signals rarely align with linguistic semantics. To overcome these limitations, we propose BEAT, a unified and transferable framework that tokenizes user and item behaviors into discrete, interpretable sequences. We construct a behavior vocabulary via a vector-quantized autoencoding process that disentangles macro-level interests and micro-level intentions from graph-based representations. We then introduce multi-level semantic supervision to bridge the gap between behavioral signals and language space. A semantic alignment regularization mechanism is designed to embed behavior tokens directly into the input space of frozen language models. Experiments on three public datasets show that BEAT improves zero-shot recommendation performance while generating coherent and informative explanations. Further analysis demonstrates that our behavior tokens capture fine-grained semantics and offer a plug-and-play interface for integrating complex behavior patterns into large language models.

</details>


### [105] [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)
*Tianze Luo,Haotian Yuan,Zhuang Liu*

Main category: cs.LG

TL;DR: SoFlow模型通过分析速度函数与ODE解函数的关系，提出Flow Matching损失和解一致性损失，实现从零开始的一步生成，无需计算JVP，在ImageNet 256×256上优于MeanFlow模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型和Flow Matching模型的多步去噪过程存在效率问题，这促使研究者探索少步生成方法。本文旨在解决从零开始的一步生成问题。

Method: 提出Solution Flow Models (SoFlow)框架，通过分析速度ODE中速度函数与解函数的关系，设计Flow Matching损失和无需计算Jacobian-vector product的解一致性损失来训练模型。Flow Matching损失使模型能在训练期间为Classifier-Free Guidance提供估计速度场。

Result: 在相同Diffusion Transformer架构和训练轮数下，SoFlow模型在ImageNet 256×256数据集上获得了比MeanFlow模型更好的FID-50K分数。

Conclusion: SoFlow框架成功实现了一步生成，通过创新的损失函数设计避免了JVP计算，在生成质量和效率方面表现出优势。

Abstract: The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity function and the solution function of the velocity ordinary differential equation (ODE), we propose a Flow Matching loss and a solution consistency loss to train our models. The Flow Matching loss allows our models to provide estimated velocity fields for Classifier-Free Guidance (CFG) during training, which improves generation performance. Notably, our consistency loss does not require the calculation of the Jacobian-vector product (JVP), a common requirement in recent works that is not well-optimized in deep learning frameworks like PyTorch. Experimental results indicate that, when trained from scratch using the same Diffusion Transformer (DiT) architecture and an equal number of training epochs, our models achieve better FID-50K scores than MeanFlow models on the ImageNet 256x256 dataset.

</details>


### [106] [A Multivariate Statistical Framework for Detection, Classification and Pre-localization of Anomalies in Water Distribution Networks](https://arxiv.org/abs/2512.15685)
*Oleg Melnikov,Yurii Dorofieiev,Yurii Shakhnovskiy,Huy Truong,Victoria Degeler*

Main category: cs.LG

TL;DR: SICAMS框架通过多元统计分析检测、分类和初步定位供水管网异常，无需校准水力模型


<details>
  <summary>Details</summary>
Motivation: 供水管网异常检测需要处理异构传感器数据，现有方法通常依赖校准的水力模型，开发无需模型校准的统计检测框架

Method: 使用白化变换消除压力流量数据的空间相关性，构建Hotelling's T²统计量进行假设检验，开发启发式算法分类异常类型，基于统计贡献度排序传感器并采用拉普拉斯插值进行粗定位

Result: 在BattLeDIM L-Town基准数据集上表现出高灵敏度和可靠性，即使在多重泄漏情况下仍保持稳健性能，T²统计量与总泄漏量相关可用于估算水损失

Conclusion: SICAMS框架为供水管网异常检测提供了无需校准水力模型的实用解决方案，适用于实际运营环境

Abstract: This paper presents a unified framework, for the detection, classification, and preliminary localization of anomalies in water distribution networks using multivariate statistical analysis. The approach, termed SICAMS (Statistical Identification and Classification of Anomalies in Mahalanobis Space), processes heterogeneous pressure and flow sensor data through a whitening transformation to eliminate spatial correlations among measurements. Based on the transformed data, the Hotelling's $T^2$ statistic is constructed, enabling the formulation of anomaly detection as a statistical hypothesis test of network conformity to normal operating conditions. It is shown that Hotelling's $T^2$ statistic can serve as an integral indicator of the overall "health" of the system, exhibiting correlation with total leakage volume, and thereby enabling approximate estimation of water losses via a regression model. A heuristic algorithm is developed to analyze the $T^2$ time series and classify detected anomalies into abrupt leaks, incipient leaks, and sensor malfunctions. Furthermore, a coarse leak localization method is proposed, which ranks sensors according to their statistical contribution and employs Laplacian interpolation to approximate the affected region within the network. Application of the proposed framework to the BattLeDIM L-Town benchmark dataset demonstrates high sensitivity and reliability in leak detection, maintaining robust performance even under multiple leaks. These capabilities make the method applicable to real-world operational environments without the need for a calibrated hydraulic model.

</details>


### [107] [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)
*Matin Mortaheb,Erciyes Karakaya,Sennur Ulukus*

Main category: cs.LG

TL;DR: 提出了一种多模态语义通信框架，通过文本查询引导视觉信息提取，使用跨模态注意力机制和自适应分辨率传输，在带宽受限环境下实现高效语义通信。


<details>
  <summary>Details</summary>
Motivation: 传统基于transformer的语义通信方法在复杂多目标场景中表现不佳，因为自注意力机制缺乏明确的任务指导。需要一种能够结合用户查询来引导信息提取的语义通信框架。

Method: 提出多模态语义通信框架，使用跨模态注意力机制融合视觉特征和语言嵌入，生成软相关性分数。基于这些分数和瞬时信道带宽，采用自适应分辨率传输算法，使用独立训练的编码器-解码器对传输图像块，总比特率匹配信道容量。

Result: 接收端能够重建并组合图像块，保留任务关键信息。该框架在复杂和带宽受限环境中实现了高效的语义通信。

Conclusion: 提出的多模态语义通信框架通过文本查询引导信息提取，结合自适应分辨率传输，为复杂场景下的语义通信提供了灵活且目标驱动的解决方案，显著提高了通信效率。

Abstract: Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to identify informative regions within images, but they often struggle in complex scenes with multiple objects, where self-attention lacks explicit task guidance. To address this, we propose a novel Multi-Modal Semantic Communication framework that integrates text-based user queries to guide the information extraction process. Our proposed system employs a cross-modal attention mechanism that fuses visual features with language embeddings to produce soft relevance scores over the visual data. Based on these scores and the instantaneous channel bandwidth, we use an algorithm to transmit image patches at adaptive resolutions using independently trained encoder-decoder pairs, with total bitrate matching the channel capacity. At the receiver, the patches are reconstructed and combined to preserve task-critical information. This flexible and goal-driven design enables efficient semantic communication in complex and bandwidth-constrained environments.

</details>


### [108] [FrontierCS: Evolving Challenges for Evolving Intelligence](https://arxiv.org/abs/2512.15699)
*Qiuyang Mang,Wenhao Chai,Zhifei Li,Huanzhi Mao,Shang Zhou,Alexander Du,Hanchen Li,Shu Liu,Edwin Chen,Yichuan Wang,Xieting Chu,Zerui Cheng,Yuan Xu,Tian Xia,Zirui Wang,Tianneng Shi,Jianzhu Yao,Yilong Zhao,Qizheng Zhang,Charlie Ruan,Zeyu Shen,Kaiyuan Liu,Runyuan He,Dong Xing,Zerui Li,Zirong Zeng,Yige Jiang,Lufeng Cheng,Ziyi Zhao,Youran Sun,Wesley Zheng,Meiyuwang Zhang,Ruyi Ji,Xuechang Tu,Zihan Zheng,Zexing Chen,Kangyang Zhou,Zhaozi Wang,Jingbang Chen,Aleksandra Korolova,Peter Henderson,Pramod Viswanath,Vijay Ganesh,Saining Xie,Zhuang Liu,Dawn Song,Sewon Min,Ion Stoica,Joseph E. Gonzalez,Jingbo Shang,Alvin Cheung*

Main category: cs.LG

TL;DR: FrontierCS是一个包含156个开放式计算机科学问题的基准测试，这些问题由专家设计，旨在评估模型在未知最优解但可客观评估解决方案质量的任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注已知最优解的任务，而缺乏评估模型在真正前沿、开放式计算机科学问题上的能力。需要创建一个能够客观评估模型在未知最优解但可量化评估解决方案质量的复杂问题上的表现的基准。

Method: 创建了包含156个开放式问题的基准测试，涵盖算法问题和研究问题。每个问题都提供专家参考解决方案和自动评估器。模型通过实现可执行程序而非直接输出答案来解决问题。算法问题通常是NP难的竞争编程问题变体，具有客观部分评分机制。

Result: 前沿推理模型在算法和研究两个轨道上都远远落后于人类专家。仅增加推理预算无法缩小这一差距。模型往往过度优化生成仅能工作的代码，而不是发现高质量的算法和系统设计。

Conclusion: FrontierCS提供了一个位于计算机科学难度前沿的基准测试，结合了开放式设计、可测量进展和专家策划。研究表明当前模型在解决真正前沿的计算机科学问题上仍有很大提升空间。

Abstract: We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [109] [Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis](https://arxiv.org/abs/2512.15398)
*Zanxiang He,Meng Li,Liyun Shi,Weiye Daia,Liming Nie*

Main category: cs.MA

TL;DR: Mapis是一个基于知识图谱的多智能体框架，专门用于基于指南的多囊卵巢综合征诊断，通过模拟临床诊断流程显著提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: PCOS影响10%的育龄女性，现有机器学习方法依赖大规模标注数据且缺乏可解释性，多智能体系统在PCOS检测中尚未充分探索，现有医疗多智能体框架缺乏领域特定知识。

Method: 将2023年国际指南转化为结构化协作工作流，模拟临床诊断过程，包括妇科内分泌智能体、放射科智能体协作验证纳入标准，排除智能体严格排除其他病因，并构建全面的PCOS知识图谱支持基于证据的决策。

Result: 在公共基准和专门临床数据集上，Mapis显著优于9个不同基线方法。在临床数据集上，准确率比传统机器学习模型高13.56%，比单智能体高6.55%，比先前医疗多智能体系统高7.05%。

Conclusion: Mapis是首个专门为基于指南的PCOS诊断设计的知识驱动多智能体框架，通过模拟临床工作流程和整合领域知识，在准确性和可解释性方面取得了显著改进。

Abstract: Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.

</details>
